<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Using secrets in Kafka Connect configuration</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/7g0HclFyA5I/" /><category term="CI/CD" /><category term="Containers" /><category term="Kubernetes" /><category term="amq streams" /><category term="kafka connect" /><category term="openshift" /><category term="secrets" /><category term="Strimzi" /><author><name>Jakub Scholz</name></author><id>https://developers.redhat.com/blog/?p=680387</id><updated>2020-02-14T08:00:38Z</updated><published>2020-02-14T08:00:38Z</published><content type="html">&lt;p&gt;Kafka Connect is an integration framework that is part of the &lt;a href="http://kafka.apache.org/" target="_blank" rel="noopener noreferrer"&gt;Apache Kafka&lt;/a&gt; project. On Kubernetes and &lt;a href="http://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt;, you can deploy Kafka Connect using the &lt;a href="https://strimzi.io/" target="_blank" rel="noopener noreferrer"&gt;Strimzi&lt;/a&gt; and &lt;a href="https://www.redhat.com/en/products/integration" target="_blank" rel="noopener noreferrer"&gt;Red Hat AMQ Streams&lt;/a&gt; Operators. Kafka Connect lets users run sink and source connectors. Source connectors are used to load data from an external system into Kafka. Sink connectors work the other way around and let you load data from Kafka into another external system. In most cases, the connectors need to authenticate when connecting to the other systems, so you will need to provide credentials as part of the connector&amp;#8217;s configuration. This article shows you how you can use Kubernetes secrets to store the credentials and then use them in the connector&amp;#8217;s configuration.&lt;/p&gt; &lt;p&gt;&lt;span id="more-680387"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;In this article, I will use an S3 source connector, which is one of the Apache Camel Kafka connectors. To learn more about Apache Camel Kafka connectors, you can start with &lt;a href="https://camel.apache.org/blog/Camel-Kafka-connector-intro/" target="_blank" rel="noopener noreferrer"&gt;this blog post&lt;/a&gt;. This connector is used just as an example of how to configure a connector to access a secret. You can use this same procedure with any connector, as there is nothing special required from the connector itself. We will use the S3 connector to connect to Amazon AWS S3 storage and load files from an S3 bucket into an Apache Kafka topic. In order to connect to S3 storage, we will need to specify the AWS credentials: the access key and the secret key. So, let’s start by preparing the secret with the credentials.&lt;/p&gt; &lt;h2&gt;Creating a secret with the credentials&lt;/h2&gt; &lt;p&gt;First, we will create a simple properties file called &lt;code&gt;aws-credentials.properties&lt;/code&gt;, which should look like this:&lt;/p&gt; &lt;pre&gt;aws_access_key_id=AKIAIOSFODNN7EXAMPLE aws_secret_access_key=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY&lt;/pre&gt; &lt;p&gt;The credentials you use in this properties file need to have access to the S3 bucket we will read from. Once we have the properties file with the credentials ready, we have to create the secret from this file. You can use the following command to do so:&lt;/p&gt; &lt;pre&gt;$ kubectl create secret generic aws-credentials --from-file=./aws-credentials.properties&lt;/pre&gt; &lt;h2&gt;Building new container images with the connector&lt;/h2&gt; &lt;p&gt;Next, we need to prepare a new Docker image with our connector. When using Strimzi, the &lt;code&gt;Dockerfile&lt;/code&gt; for adding the connector should look something like this:&lt;/p&gt; &lt;pre&gt;FROM strimzi/kafka:0.16.1-kafka-2.4.0 USER root:root COPY ./my-plugins/ /opt/kafka/plugins/ USER 1001&lt;/pre&gt; &lt;p&gt;When using AMQ Streams, it should look like this:&lt;/p&gt; &lt;pre&gt;FROM registry.redhat.io/amq7/amq-streams-kafka-23:1.3.0 USER root:root COPY ./my-plugins/ /opt/kafka/plugins/ USER jboss:jboss&lt;/pre&gt; &lt;p&gt;Use the &lt;code&gt;Dockerfile&lt;/code&gt; to build a container image with the connectors you need, and push them into your registry. If you don’t have your own private registry, you can use one of the public registries such as &lt;a href="https://quay.io/" target="_blank" rel="noopener noreferrer"&gt;Quay&lt;/a&gt; or &lt;a href="https://hub.docker.com/" target="_blank" rel="noopener noreferrer"&gt;Docker Hub&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Deploying Apache Kafka Connect&lt;/h2&gt; &lt;p&gt;Once we have the container image, we can finally deploy Apache Kafka Connect. You can do this by creating the following custom resource:&lt;/p&gt; &lt;pre&gt;apiVersion: kafka.strimzi.io/v1alpha1 kind: KafkaConnect metadata:   name: my-connect-cluster spec:   image: docker.io/scholzj/kafka:camel-kafka-2.4.0   replicas: 3   bootstrapServers: my-cluster-kafka-bootstrap:9092   externalConfiguration:     volumes:       - name: aws-credentials         secret:           secretName: aws-credentials   config:     config.providers: file     config.providers.file.class: org.apache.kafka.common.config.provider.FileConfigProvider     key.converter: org.apache.kafka.connect.json.JsonConverter     value.converter: org.apache.kafka.connect.json.JsonConverter     key.converter.schemas.enable: false     value.converter.schemas.enable: false&lt;/pre&gt; &lt;p&gt;Let’s look in more detail at several parts of the custom resource. First of all, notice the &lt;code&gt;image&lt;/code&gt; field, which tells the Operator deploying Apache Kafka Connect to use the right image with the added connectors. In my case, I pushed the container image built in previous section to Docker Hub as &lt;code&gt;scholzj/kafka:camel-kafka-2.4.0&lt;/code&gt;, so my configuration looks like this:&lt;/p&gt; &lt;pre&gt;image: docker.io/scholzj/kafka:camel-kafka-2.4.0&lt;/pre&gt; &lt;p&gt;Next, notice the &lt;code&gt;externalConfiguration&lt;/code&gt; section:&lt;/p&gt; &lt;pre&gt;externalConfiguration:   volumes:     - name: aws-credentials       secret:         secretName: aws-credentials&lt;/pre&gt; &lt;p&gt;In this section, we instruct the Operator to mount the Kubernetes secret &lt;code&gt;aws-credentials&lt;/code&gt;that we created at the beginning of this article into the Apache Kafka Connect pods. The secrets listed here will be mounted in the path &lt;code&gt;/opt/kafka/external-configuration/&amp;#60;secretName&amp;#62;&lt;/code&gt; where the &lt;code&gt;&amp;#60;secretName&amp;#62;&lt;/code&gt; is the name of the secret.&lt;/p&gt; &lt;p&gt;And finally, in the config section, we enable the &lt;code&gt;FileConfigProvider&lt;/code&gt; as a configuration provider in Apache Kafka Connect:&lt;/p&gt; &lt;pre&gt;config:   config.providers: file   config.providers.file.class: org.apache.kafka.common.config.provider.FileConfigProvider&lt;/pre&gt; &lt;p&gt;Configuration providers are a way of loading configuration values from another source instead of specifying them in the configuration directly. In this case, we create the configuration provider namef &lt;code&gt;file&lt;/code&gt;, which will use the &lt;code&gt;FileConfigProvider&lt;/code&gt; class. This configuration provider is part of Apache Kafka. &lt;code&gt;FileConfigProvider&lt;/code&gt; can read properties files and extract values from them, and we will use it to load API keys for our Amazon AWS account.&lt;/p&gt; &lt;h2&gt;Creating the connector using the Apache Kafka Connect REST API&lt;/h2&gt; &lt;p&gt;Usually, we have to wait a minute or two for the Apache Kafka Connect deployment to become ready. And once it &lt;em&gt;is&lt;/em&gt; ready, we can create the connector instance. In older versions of Strimzi and Red Hat AMQ Streams, you have to do that using the REST API. We can create the connector by posting the following JSON:&lt;/p&gt; &lt;pre&gt;{  "name": "s3-connector",  "config": {    "connector.class": "org.apache.camel.kafkaconnector.CamelSourceConnector",    "tasks.max": "1",    "camel.source.kafka.topic": "s3-topic",    "camel.source.maxPollDuration": "10000",    "camel.source.url": "aws-s3://camel-connector-test?autocloseBody=false",    "key.converter": "org.apache.kafka.connect.storage.StringConverter",   "value.converter": "org.apache.camel.kafkaconnector.converters.S3ObjectConverter",    "camel.component.aws-s3.configuration.access-key": "${file:/opt/kafka/external-configuration/aws-credentials/aws-credentials.properties:aws_access_key_id}",    "camel.component.aws-s3.configuration.secret-key": "${file:/opt/kafka/external-configuration/aws-credentials/aws-credentials.properties:aws_secret_access_key}",   "camel.component.aws-s3.configuration.region": "US_EAST_1"    } }&lt;/pre&gt; &lt;p&gt;The connector configuration contains the AWS API keys in the fields &lt;code&gt;camel.component.aws-s3.configuration.access-key&lt;/code&gt; and &lt;code&gt;camel.component.aws-s3.configuration.secret-key&lt;/code&gt;. Instead of using the values directly, we just reference the file configuration provider to load the fields &lt;code&gt;aws_access_key_id&lt;/code&gt; and &lt;code&gt;aws_secret_access_key&lt;/code&gt; from our &lt;code&gt;aws-credentials.properties&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;Notice how we reference the config provider, tell it the path to the file it should use, and include the name of the key to extract:&lt;/p&gt; &lt;pre&gt;"camel.component.aws-s3.configuration.access-key": "${file:/opt/kafka/external-configuration/aws-credentials/aws-credentials.properties:aws_access_key_id}"&lt;/pre&gt; &lt;p&gt;and:&lt;/p&gt; &lt;pre&gt;"camel.component.aws-s3.configuration.secret-key": "${file:/opt/kafka/external-configuration/aws-credentials/aws-credentials.properties:aws_secret_access_key}"&lt;/pre&gt; &lt;p&gt;You can &lt;code&gt;POST&lt;/code&gt; the results to the Apache Kafka Connect REST API, for example, using &lt;code&gt;curl&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;$ curl -X POST -H "Content-Type: application/json" -d connector-config.json http://my-connect-cluster-connect-api:8083/connectors&lt;/pre&gt; &lt;p&gt;One of the advantages of using the configuration providers is that even when you later get the connector configuration, it will still contain the configuration provider and not the values you want to keep secret:&lt;/p&gt; &lt;pre&gt;$ curl http://my-connect-cluster-connect-api:8083/connectors/s3-connector {   "name": "s3-connector",   "config": {     "connector.class": "org.apache.camel.kafkaconnector.CamelSourceConnector",     "camel.source.maxPollDuration": "10000",     "camel.source.url": "aws-s3://camel-connector-test?autocloseBody=false",     "camel.component.aws-s3.configuration.region": "US_EAST_1",     "camel.component.aws-s3.configuration.secret-key": "${file:/opt/kafka/external-configuration/aws-credentials/aws-credentials.properties:aws_secret_access_key}",     "tasks.max": "1",     "name": "s3-connector",     "value.converter": "org.apache.camel.kafkaconnector.converters.S3ObjectConverter",     "camel.component.aws-s3.configuration.access-key": "${file:/opt/kafka/external-configuration/aws-credentials/aws-credentials.properties:aws_access_key_id}",     "key.converter": "org.apache.kafka.connect.storage.StringConverter",     "camel.source.kafka.topic": "s3-topic"   },   "tasks": [     {       "connector": "s3-connector",       "task": 0     }   ],   "type": "source" }&lt;/pre&gt; &lt;h2&gt;Creating the connector with the Strimzi connector Operator&lt;/h2&gt; &lt;p&gt;When using Strimzi 0.16.0 or newer, we can also use the new connector Operator. It lets us create the connector using the following custom resource YAML (you can use the configuration provider directly in the &lt;code&gt;KafkaConnector&lt;/code&gt; custom resource as well):&lt;/p&gt; &lt;pre&gt;apiVersion: kafka.strimzi.io/v1alpha1 kind: KafkaConnector metadata:   name: s3-connector   labels:     strimzi.io/cluster: my-connect-cluster spec:   class: org.apache.camel.kafkaconnector.CamelSourceConnector   tasksMax: 1   config:     key.converter: org.apache.kafka.connect.storage.StringConverter     value.converter: org.apache.camel.kafkaconnector.converters.S3ObjectConverter     camel.source.kafka.topic: s3-topic     camel.source.url: aws-s3://camel-connector-test?autocloseBody=false     camel.source.maxPollDuration: 10000     camel.component.aws-s3.configuration.access-key: ${file:/opt/kafka/external-configuration/aws-credentials/aws-credentials.properties:aws_access_key_id}     camel.component.aws-s3.configuration.secret-key: ${file:/opt/kafka/external-configuration/aws-credentials/aws-credentials.properties:aws_secret_access_key}     camel.component.aws-s3.configuration.region: US_EAST_1&lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The security of Kubernetes secrets has its limitations, any user who can exec into the container will be able to read the mounted secrets anyway. This process at least prevents the confidential information, such as credentials or API keys, from being exposed through the REST API or in the &lt;code&gt;KafkaConnector&lt;/code&gt; custom resources.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F14%2Fusing-secrets-in-apache-kafka-connect-configuration%2F&amp;#38;linkname=Using%20secrets%20in%20Kafka%20Connect%20configuration" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F14%2Fusing-secrets-in-apache-kafka-connect-configuration%2F&amp;#38;linkname=Using%20secrets%20in%20Kafka%20Connect%20configuration" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F14%2Fusing-secrets-in-apache-kafka-connect-configuration%2F&amp;#38;linkname=Using%20secrets%20in%20Kafka%20Connect%20configuration" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F14%2Fusing-secrets-in-apache-kafka-connect-configuration%2F&amp;#38;linkname=Using%20secrets%20in%20Kafka%20Connect%20configuration" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F14%2Fusing-secrets-in-apache-kafka-connect-configuration%2F&amp;#38;linkname=Using%20secrets%20in%20Kafka%20Connect%20configuration" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F14%2Fusing-secrets-in-apache-kafka-connect-configuration%2F&amp;#38;linkname=Using%20secrets%20in%20Kafka%20Connect%20configuration" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F14%2Fusing-secrets-in-apache-kafka-connect-configuration%2F&amp;#38;linkname=Using%20secrets%20in%20Kafka%20Connect%20configuration" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F14%2Fusing-secrets-in-apache-kafka-connect-configuration%2F&amp;#038;title=Using%20secrets%20in%20Kafka%20Connect%20configuration" data-a2a-url="https://developers.redhat.com/blog/2020/02/14/using-secrets-in-apache-kafka-connect-configuration/" data-a2a-title="Using secrets in Kafka Connect configuration"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/14/using-secrets-in-apache-kafka-connect-configuration/"&gt;Using secrets in Kafka Connect configuration&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/7g0HclFyA5I" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Kafka Connect is an integration framework that is part of the Apache Kafka project. On Kubernetes and Red Hat OpenShift, you can deploy Kafka Connect using the Strimzi and Red Hat AMQ Streams Operators. Kafka Connect lets users run sink and source connectors. Source connectors are used to load data from an external system into [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/14/using-secrets-in-apache-kafka-connect-configuration/"&gt;Using secrets in Kafka Connect configuration&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">680387</post-id><dc:creator>Jakub Scholz</dc:creator><dc:date>2020-02-14T08:00:38Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/02/14/using-secrets-in-apache-kafka-connect-configuration/</feedburner:origLink></entry><entry><title>OpenShift Actions: Deploy to Red Hat OpenShift directly from your GitHub repository</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/G0VmD1caDRU/" /><category term="CI/CD" /><category term="Developer Tools" /><category term="DevOps" /><category term="development workflow" /><category term="github actions" /><category term="OpenShift Actions" /><category term="SDLC" /><author><name>Luca Stocchi</name></author><id>https://developers.redhat.com/blog/?p=676347</id><updated>2020-02-13T08:00:26Z</updated><published>2020-02-13T08:00:26Z</published><content type="html">&lt;p&gt;Here is a common situation: You write your code, everything is on GitHub, and you are ready to publish it. But, you know that your job is not finished yet. You need to deploy your code and this process can be a nightmare at times.&lt;/p&gt; &lt;p&gt;Ideally, you should be able to do this whole process all in one place, but until now, you always had to set up external services and integrate them with GitHub (or add post-commit hooks). What if, instead, you could replace all of these extras and run everything directly from your GitHub repository with just a few YAML lines? Well, this is exactly what GitHub Actions are for.&lt;/p&gt; &lt;p&gt;&lt;span id="more-676347"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;GitHub Actions are a new feature recently introduced by GitHub. They enable users to set up custom software development life cycle (SDLC) workflows directly from their GitHub repositories. By using actions, developers can let GitHub take care of a number of processes that can be triggered by a &lt;a href="https://help.github.com/en/actions/automating-your-workflow-with-github-actions/events-that-trigger-workflows" target="_blank" rel="noopener noreferrer"&gt;variety of events&lt;/a&gt; on the platform, like pushing code, making a release, and so on. This way, you can let GitHub deploy your app every time an event occurs and just focus on your code.&lt;/p&gt; &lt;p&gt;Although GitHub Actions is still quite new, we could not wait to make an action and let developers connect and deploy to their &lt;a href="http://developers.redhat.com/openshift/" target="_blank" rel="noopener noreferrer"&gt;Red Hat OpenShift&lt;/a&gt; cluster directly from their GitHub repository. In this article, we will take a quick look at the &lt;a href="https://github.com/redhat-developer/openshift-actions" target="_blank" rel="noopener noreferrer"&gt;OpenShift Actions&lt;/a&gt; extension and show how easy it is to set up and use.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; OpenShift Actions can be downloaded from the GitHub marketplace directly from &lt;a href="https://github.com/marketplace/actions/openshift-action" target="_blank" rel="noopener noreferrer"&gt;this link&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Using OpenShift Actions&lt;/h3&gt; &lt;p&gt;To use OpenShift Actions in your GitHub repository, start by creating your workflow and saving it as a YAML file in &lt;code&gt;.github/workflows/&amp;#60;file name&amp;#62;.yml&lt;/code&gt;. By clicking on the &lt;strong&gt;Actions&lt;/strong&gt; tab (on top of your repository, next to &lt;strong&gt;Pull request&lt;/strong&gt;) you will be shown the most popular continuous integration workflows and you will be guided to set up your own, as shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_676417" style="width: 565px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-676417" class="wp-image-676417 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/oc-action-1.png" alt="new workflow in the GitHub Actions tab" width="555" height="222" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/oc-action-1.png 555w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/oc-action-1-300x120.png 300w" sizes="(max-width: 555px) 100vw, 555px" /&gt;&lt;p id="caption-attachment-676417" class="wp-caption-text"&gt;Figure 1: Your new workflow in GitHub.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;As you can see in the example below, you can define the events that trigger your workflow, the runner to execute each job (e.g., different types and versions of virtual host machines, including Linux, Windows, and macOS), and all of the actions to run:&lt;/p&gt; &lt;pre&gt;name: CI on: # Trigger the workflow on push to the master branch push: branches: - master jobs: build: runs-on: ubuntu-latest steps: - name: OpenShift Action uses: redhat-developer/openshift-actions@v1.1 with: version: 'latest' openshift_server_url: ${{ secrets.OPENSHIFT_SERVER_URL }} parameters: '{"apitoken": "${{ secrets.API_TOKEN }}", "acceptUntrustedCerts": "true"}' cmd: | 'version' 'start-build &lt;span class="x x-first x-last"&gt;nodejs-ex&lt;/span&gt; --follow' 'status' &lt;/pre&gt; &lt;p&gt;In our example, we want to deploy our application on OpenShift every time something is pushed to our master. For this reason, we configure our workflow to start when the event push occurs and also specify the branch we are interested in, the master. If the branch is omitted, the workflow will trigger on each push made to the repository.&lt;/p&gt; &lt;p&gt;Next, we need to specify whether to use a GitHub-hosted or self-hosted runner. GitHub only provides runners on Windows Server 2019, Linux Ubuntu 16.04/18.04, and macOS Catalina 10.15. If you want to have your own runner on &lt;a href="http://developers.redhat.com/rhel8/"&gt;Red Hat Enterprise Linux&lt;/a&gt;/&lt;a href="https://www.centos.org/" target="_blank" rel="noopener noreferrer"&gt;CentOS&lt;/a&gt;/&lt;a href="https://getfedora.org/" target="_blank" rel="noopener noreferrer"&gt;Fedora&lt;/a&gt;, you have to choose self-hosted. Here is a list of &lt;a href="https://help.github.com/en/actions/automating-your-workflow-with-github-actions/about-self-hosted-runners#differences-between-github-hosted-and-self-hosted-runners" target="_blank" rel="noopener noreferrer"&gt;all supported operating systems.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Finally, we need to set up all of the actions (steps) we want to execute. In this case, we are just deploying our application to our OpenShift cluster using our OpenShift action, but you could also add another action to send an email or an SMS to someone, or run tests. Just use your imagination.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; In this example, we are using OpenShift Actions v1.1. To use the latest release, &lt;a href="https://github.com/marketplace/actions/openshift-action" target="_blank" rel="noopener noreferrer"&gt;go to the marketplace&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;OpenShift action inputs&lt;/h3&gt; &lt;p&gt;You can see that the OpenShift action requires inputs to run. Let’s look at what they are and what they are for:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;&lt;code&gt;version&lt;/code&gt; &lt;em&gt;(optional):&lt;/em&gt;&lt;/strong&gt; The version of the &lt;code&gt;oc&lt;/code&gt; CLI that we want the OpenShift Actions to use when executing commands. This input accepts three different values: &lt;ul&gt; &lt;li&gt;&lt;strong&gt;version number&lt;/strong&gt; (i.e., &lt;code&gt;3.11.36&lt;/code&gt;)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;URL for downloading the oc bundle&lt;/strong&gt; (i.e., &lt;code&gt;https://mirror.openshift.com/pub/openshift-v3/clients/3.11.36/linux/oc.tar.gz&lt;/code&gt;)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;version&lt;/strong&gt;: &lt;ul&gt; &lt;li&gt;Used in the form &lt;code&gt;version: 'latest'&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Downloads the latest version available.&lt;/li&gt; &lt;li&gt;Acts as the default value for this input.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;strong&gt;&lt;code&gt;openshift_server_url&lt;/code&gt; &lt;em&gt;(required):&lt;/em&gt;&lt;/strong&gt; The URL for the OpenShift cluster, used in the form &lt;code&gt;openshift_server_url: ${{ secrets.OPENSHIFT_SERVER_URL }}&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;&lt;code&gt;parameters&lt;/code&gt; &lt;em&gt;(required):&lt;/em&gt;&lt;/strong&gt; A JSON string with the values needed to connect to the OpenShift cluster. Must be in the form &lt;code&gt;parameters: '{"apitoken": "${{ secrets.API_TOKEN }}", "acceptUntrustedCerts": "true"}'&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;&lt;code&gt;cmd&lt;/code&gt;&lt;em&gt; (required):&lt;/em&gt;&lt;/strong&gt; One or more &lt;code&gt;oc&lt;/code&gt; commands to be executed.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;OpenShift action authentication&lt;/h3&gt; &lt;p&gt;To allow the extension to connect to our cluster, we need to configure an OpenShift connection. The &lt;code&gt;parameters&lt;/code&gt; input is used for this purpose. Based on its value, one of two supported authentication methods will be used: basic or token.&lt;/p&gt; &lt;h4&gt;Basic authentication&lt;/h4&gt; &lt;p&gt;The &lt;code&gt;parameters&lt;/code&gt; input uses a username and password to connect to the cluster, i.e., &lt;code&gt;parameters: '{"username": "${{ secrets.USERNAME }}", "password": "${{ secrets.PASSWORD }}", "acceptUntrustedCerts": "true"}'&lt;/code&gt;&lt;/p&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th style="text-align: left;"&gt;&lt;b&gt;Name&lt;/b&gt;&lt;/th&gt; &lt;th style="text-align: left;"&gt;&lt;b&gt;Requirement&lt;/b&gt;&lt;/th&gt; &lt;th style="text-align: left;"&gt;&lt;b&gt;Description&lt;/b&gt;&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;username&lt;/code&gt;&lt;/td&gt; &lt;td&gt;&lt;em&gt;required&lt;/em&gt;&lt;/td&gt; &lt;td&gt;The OpenShift username.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;password&lt;/code&gt;&lt;/td&gt; &lt;td&gt;&lt;em&gt;required&lt;/em&gt;&lt;/td&gt; &lt;td&gt;The password for the specified user.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;acceptUntrustedCerts&lt;/code&gt;&lt;/td&gt; &lt;td&gt;&lt;em&gt;optional&lt;/em&gt;&lt;/td&gt; &lt;td&gt;Whether it is ok to accept self-signed (untrusted) certificates.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;certificateAuthorityFile&lt;/code&gt;&lt;/td&gt; &lt;td&gt;&lt;em&gt;optional&lt;/em&gt;&lt;/td&gt; &lt;td&gt;The path to where the certificate authority file is stored.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h4&gt;Token authentication&lt;/h4&gt; &lt;p&gt;The &lt;code&gt;parameters&lt;/code&gt; input uses an API token to connect to the cluster, i.e., &lt;code&gt;parameters: '{"apitoken": "${{ secrets.API_TOKEN }}"}'&lt;/code&gt;.&lt;/p&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th style="text-align: left;"&gt;&lt;b&gt;Name&lt;/b&gt;&lt;/th&gt; &lt;th style="text-align: left;"&gt;&lt;b&gt;Requirement&lt;/b&gt;&lt;/th&gt; &lt;th style="text-align: left;"&gt;&lt;b&gt;Description&lt;/b&gt;&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;apitoken&lt;/code&gt;&lt;/td&gt; &lt;td&gt;&lt;em&gt;required&lt;/em&gt;&lt;/td&gt; &lt;td&gt;The API token used for authentication.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;acceptUntrustedCerts&lt;/code&gt;&lt;/td&gt; &lt;td&gt;&lt;em&gt;optional&lt;/em&gt;&lt;/td&gt; &lt;td&gt;Whether it is ok to accept self-signed (untrusted) certificate.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;certificateAuthorityFile&lt;/code&gt;&lt;/td&gt; &lt;td&gt;&lt;em&gt;optional&lt;/em&gt;&lt;/td&gt; &lt;td&gt;The path where the certificate authority file is stored.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h3&gt;Secrets&lt;/h3&gt; &lt;p&gt;As you can see above, we never write our sensitive data in the clear. We always use &lt;em&gt;secrets&lt;/em&gt;. Even though this setup is not mandatory, we highly suggest using secrets when needed.&lt;/p&gt; &lt;p&gt;Secrets are encrypted environment variables created in a repository and are only used by GitHub Actions. GitHub encrypts secrets in the web browser using public key-authenticated encryption and the Poly1305 cipher algorithm. For more information, see &lt;a href="https://github.com/dchest/tweetnacl-js#public-key-authenticated-encryption-box" target="_blank" rel="noopener noreferrer"&gt;the &lt;code&gt;TweetNaCl.js&lt;/code&gt; documentation&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;To make a secret available to an action, you must set it in your repository and then add it as an input or environment variable in the workflow file.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; For an organization&amp;#8217;s repository, you must have &lt;em&gt;admin&lt;/em&gt; access in order to create encrypted secrets. For a user account repository, you must be the repository &lt;em&gt;owner&lt;/em&gt; to create encrypted secrets.&lt;/p&gt; &lt;p&gt;Here is how to create a secret:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Go to the main page of your repository.&lt;/li&gt; &lt;li&gt;Click on &lt;strong&gt;Settings&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;In the left sidebar, select &lt;strong&gt;Secrets&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Type a name for your secret in the &lt;strong&gt;Name&lt;/strong&gt; input box. (Secret names must be unique and cannot contain any spaces.)&lt;/li&gt; &lt;li&gt;Type the value for your secret. (To ensure that GitHub redacts your secret in logs, avoid using structured data as the values of secrets. Avoid creating secrets that contain JSON or encoded Git blobs.)&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Add secret&lt;/strong&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; Your workflow can have up to 100 secrets.&lt;/p&gt; &lt;h2&gt;Final words&lt;/h2&gt; &lt;p&gt;At this point, you should be able to set up your workflow and see the OpenShift action running every time the event chosen in your YAML file is triggered. To check if your workflow is working properly, you can always visit the &lt;strong&gt;Actions&lt;/strong&gt; tab in your repository and verify that all of the steps succeeded, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_676427" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-676427" class="wp-image-676427" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/oc-actio-2.png" alt="Workflow status in the Actions tab" width="640" height="404" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/oc-actio-2.png 646w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/oc-actio-2-300x189.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-676427" class="wp-caption-text"&gt;Figure 2: Check on your workflow in your repository&amp;#8217;s &lt;strong&gt;Actions&lt;/strong&gt; tab.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;If you encounter any bugs, have any suggestions, or if you would like to have a new feature implemented, you can submit an issue through &lt;a href="https://github.com/redhat-developer/openshift-actions" target="_blank" rel="noopener noreferrer"&gt;our repo&lt;/a&gt;. OpenShift Actions is an open source project and suggestions, comments, and pull requests are always welcome.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F13%2Fopenshift-actions-deploy-to-red-hat-openshift-directly-from-your-github-repository%2F&amp;#38;linkname=OpenShift%20Actions%3A%20Deploy%20to%20Red%20Hat%20OpenShift%20directly%20from%20your%20GitHub%20repository" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F13%2Fopenshift-actions-deploy-to-red-hat-openshift-directly-from-your-github-repository%2F&amp;#38;linkname=OpenShift%20Actions%3A%20Deploy%20to%20Red%20Hat%20OpenShift%20directly%20from%20your%20GitHub%20repository" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F13%2Fopenshift-actions-deploy-to-red-hat-openshift-directly-from-your-github-repository%2F&amp;#38;linkname=OpenShift%20Actions%3A%20Deploy%20to%20Red%20Hat%20OpenShift%20directly%20from%20your%20GitHub%20repository" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F13%2Fopenshift-actions-deploy-to-red-hat-openshift-directly-from-your-github-repository%2F&amp;#38;linkname=OpenShift%20Actions%3A%20Deploy%20to%20Red%20Hat%20OpenShift%20directly%20from%20your%20GitHub%20repository" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F13%2Fopenshift-actions-deploy-to-red-hat-openshift-directly-from-your-github-repository%2F&amp;#38;linkname=OpenShift%20Actions%3A%20Deploy%20to%20Red%20Hat%20OpenShift%20directly%20from%20your%20GitHub%20repository" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F13%2Fopenshift-actions-deploy-to-red-hat-openshift-directly-from-your-github-repository%2F&amp;#38;linkname=OpenShift%20Actions%3A%20Deploy%20to%20Red%20Hat%20OpenShift%20directly%20from%20your%20GitHub%20repository" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F13%2Fopenshift-actions-deploy-to-red-hat-openshift-directly-from-your-github-repository%2F&amp;#38;linkname=OpenShift%20Actions%3A%20Deploy%20to%20Red%20Hat%20OpenShift%20directly%20from%20your%20GitHub%20repository" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F13%2Fopenshift-actions-deploy-to-red-hat-openshift-directly-from-your-github-repository%2F&amp;#038;title=OpenShift%20Actions%3A%20Deploy%20to%20Red%20Hat%20OpenShift%20directly%20from%20your%20GitHub%20repository" data-a2a-url="https://developers.redhat.com/blog/2020/02/13/openshift-actions-deploy-to-red-hat-openshift-directly-from-your-github-repository/" data-a2a-title="OpenShift Actions: Deploy to Red Hat OpenShift directly from your GitHub repository"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/13/openshift-actions-deploy-to-red-hat-openshift-directly-from-your-github-repository/"&gt;OpenShift Actions: Deploy to Red Hat OpenShift directly from your GitHub repository&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/G0VmD1caDRU" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Here is a common situation: You write your code, everything is on GitHub, and you are ready to publish it. But, you know that your job is not finished yet. You need to deploy your code and this process can be a nightmare at times. Ideally, you should be able to do this whole process [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/13/openshift-actions-deploy-to-red-hat-openshift-directly-from-your-github-repository/"&gt;OpenShift Actions: Deploy to Red Hat OpenShift directly from your GitHub repository&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">676347</post-id><dc:creator>Luca Stocchi</dc:creator><dc:date>2020-02-13T08:00:26Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/02/13/openshift-actions-deploy-to-red-hat-openshift-directly-from-your-github-repository/</feedburner:origLink></entry><entry><title>Beginners Guide - HR Employee Rewards Process Automation Workshop</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/k5vDHN1I1PE/beginners-guide-hr-rewards-process-automation-workshop.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="Process Automation Manager" scheme="searchisko:content:tags" /><category term="workshops" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-beginners_guide_hr_employee_rewards_process_automation_workshop</id><updated>2020-02-13T06:00:10Z</updated><published>2020-02-13T06:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;a href="https://bpmworkshop.gitlab.io/rhpam/#/1" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;" target="_blank"&gt;&lt;img alt="beginners guide workshops" border="0" data-original-height="771" data-original-width="1600" height="154" src="https://1.bp.blogspot.com/-En2hJjgHG_c/XkGI6ofJNBI/AAAAAAAABo4/wB00vAxZiQQ-U3vXJm7SELyt-4EO7EIJwCLcBGAsYHQ/s320/beginners-guide.png" title="" width="320" /&gt;&lt;/a&gt;The last few months there have been a series of updates to the various open source process automation technologies shared with you over the years in beginners guide workshops.&lt;br /&gt;&lt;br /&gt;These updates require updates to workshop content ensuring you have material that helps with getting hands-on with the latest technology versions.&lt;br /&gt;&lt;br /&gt;A first step is to share updates to the &lt;a href="https://bpmworkshop.gitlab.io/rhpam/#/1" target="_blank"&gt;beginners guide workshop&lt;/a&gt; that teaches the use of process automation tooling to build a human resources employee rewards process.&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;HR employee rewards &lt;/h3&gt;&lt;a href="https://bpmworkshop.gitlab.io/rhpam/#/1" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;" target="_blank"&gt;&lt;img alt="beginners guide workshops" border="0" data-original-height="666" data-original-width="1600" height="133" src="https://1.bp.blogspot.com/-uB3I6luz9og/XkGJMMl9gJI/AAAAAAAABpA/4scxfiLSbQEQhV5P4Ya2jzIrRjGThe4FwCLcBGAsYHQ/s320/toc-beginners-guide.png" title="" width="320" /&gt;&lt;/a&gt;This workshop will teach you how to build a human resources employee rewards process that integrates human tasks, email and more.&lt;br /&gt;&lt;br /&gt;Take your first steps on the road to mastering process automation integration.&lt;br /&gt;&lt;br /&gt;You'll bet led step by step through all you need to learn, design, and deploy your first process automation project.&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;br /&gt;&lt;a href="https://bpmworkshop.gitlab.io/rhpam/#/1" target="_blank"&gt;&lt;i&gt;Workshop contents&lt;/i&gt;&lt;/a&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;a href="https://1.bp.blogspot.com/-Y-1HteLesFo/XkGKVfCyvuI/AAAAAAAABpM/tps5XsraZ-QSvAkdvNfTJWEpkZfsk9VEwCLcBGAsYHQ/s1600/rewards-process.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="beginners guide workshops" border="0" data-original-height="331" data-original-width="1600" height="66" src="https://1.bp.blogspot.com/-Y-1HteLesFo/XkGKVfCyvuI/AAAAAAAABpM/tps5XsraZ-QSvAkdvNfTJWEpkZfsk9VEwCLcBGAsYHQ/s320/rewards-process.png" title="" width="320" /&gt;&lt;/a&gt;&lt;li&gt;Lab 1 - Install Red Hat Process Automation Manager&lt;/li&gt;&lt;li&gt;Lab 2 - Create a new project&lt;/li&gt;&lt;li&gt;Lab 3 - Create a domain model&lt;/li&gt;&lt;li&gt;Lab 4 - Create a process&lt;/li&gt;&lt;li&gt;Lab 5 - Completing process details&lt;/li&gt;&lt;li&gt;Lab 6 - Creating process and task forms&lt;/li&gt;&lt;li&gt;Lab 7 - Running rewards process&lt;/li&gt;&lt;/ul&gt;With all the latest updates, links to downloads for all needed product tooling on Red Hat Developers, you'll be on your way to learning process automation in no time.&lt;br /&gt;&lt;br /&gt;If you have any comments and or suggestions while using the workshop, please &lt;a href="https://gitlab.com/bpmworkshop/bpmworkshop.gitlab.io/issues/new" target="_blank"&gt;bring it to our attention&lt;/a&gt;.&amp;nbsp; &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=DCrI2MmwJA8:9cBfr_RgW4c:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=DCrI2MmwJA8:9cBfr_RgW4c:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=DCrI2MmwJA8:9cBfr_RgW4c:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=DCrI2MmwJA8:9cBfr_RgW4c:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=DCrI2MmwJA8:9cBfr_RgW4c:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=DCrI2MmwJA8:9cBfr_RgW4c:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=DCrI2MmwJA8:9cBfr_RgW4c:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=DCrI2MmwJA8:9cBfr_RgW4c:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=DCrI2MmwJA8:9cBfr_RgW4c:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=DCrI2MmwJA8:9cBfr_RgW4c:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=DCrI2MmwJA8:9cBfr_RgW4c:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/DCrI2MmwJA8" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/k5vDHN1I1PE" height="1" width="1" alt=""/&gt;</content><summary>The last few months there have been a series of updates to the various open source process automation technologies shared with you over the years in beginners guide workshops. These updates require updates to workshop content ensuring you have material that helps with getting hands-on with the latest technology versions. A first step is to share updates to the beginners guide workshop that teaches...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2020-02-13T06:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/DCrI2MmwJA8/beginners-guide-hr-rewards-process-automation-workshop.html</feedburner:origLink></entry><entry><title>Apache Camel 3.1 - More camel-core optimizations coming (Part 3)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/d_w0EQzcH50/apache-camel-31-more-camel-core.html" /><category term="apache camel" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_clausibsen" scheme="searchisko:content:tags" /><category term="roadmap" scheme="searchisko:content:tags" /><author><name>Claus Ibsen</name></author><id>searchisko:content:id:jbossorg_blog-apache_camel_3_1_more_camel_core_optimizations_coming_part_3</id><updated>2020-02-12T14:05:48Z</updated><published>2020-02-12T14:05:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;I have previously blogged about the optimizations we are doing in the next Camel 3.1 release&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;&lt;a href="http://www.davsclaus.com/2020/01/apache-camel-31-more-camel-core.html"&gt;blog part 1&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.davsclaus.com/2020/01/apache-camel-31-more-camel-core_30.html"&gt;blog part 2&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;Today I wanted to give a short update on the latest development we have done, as we are closing down on being ready to build and release Camel 3.1 as early as end of this week or the following.&lt;br /&gt;&lt;br /&gt;Since part 2, we managed to find additional 10% reduction on object allocations during routing.&lt;br /&gt;&lt;br /&gt;We have also continued the effort of configuring Camel via source code generated configurers that performs direct Java method calls vs using java bean reflections. Now all components, data formats, languages, and EIP patterns is complete. Only in more advanced use-cases where configuration is based on nested complex objects that are dynamically configured would be outside the scope of the source code configures and Camel fallback to use reflection.&lt;br /&gt;&lt;br /&gt;We also found a way to optimize property placeholder resolution on EIPs to avoid using source code generated configurers which means that there are 200 classes less to load on the classpath, and about 90kb of memory is saved. This is great as these classes and memory were only used during bootstrap of Camel, and now they are all gone.&lt;br /&gt;&lt;br /&gt;We also managed to further modulaize camel-core, so JAXB and XML routes are optional.&lt;br /&gt;Even for XML routes (not Spring or Blueprint as they have their own DOM XML parser) we have created an alternative, fast and light-weight pull based parser. The camel-example-main-xml is using this and by comparing JAXB vs Camel XML then its 6x faster (approx 1500 millis vs 250) and loads 700 classes less than JAXB.&lt;br /&gt;&lt;br /&gt;However for non XML users (eg using Java DSL) then JAXB can be avoided on the classpath at all, and you can have tiny Camel applications, such as camel-example-main-tiny with the following dependency tree (&lt;b&gt;bold are Camel JARs;&amp;nbsp;&lt;/b&gt;the example uses the bean and timer components)&lt;br /&gt;&lt;br /&gt;&lt;span style="font-family: Courier New, Courier, monospace; font-size: x-small;"&gt;[INFO] org.apache.camel.example:camel-example-main-tiny:jar:3.1.0-SNAPSHOT&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: Courier New, Courier, monospace; font-size: x-small;"&gt;&lt;b&gt;[INFO] +- org.apache.camel:camel-main:jar:3.1.0-SNAPSHOT:compile&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: Courier New, Courier, monospace; font-size: x-small;"&gt;&lt;b&gt;[INFO] |&amp;nbsp; +- org.apache.camel:camel-api:jar:3.1.0-SNAPSHOT:compile&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: Courier New, Courier, monospace; font-size: x-small;"&gt;&lt;b&gt;[INFO] |&amp;nbsp; +- org.apache.camel:camel-base:jar:3.1.0-SNAPSHOT:compile&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: Courier New, Courier, monospace; font-size: x-small;"&gt;&lt;b&gt;[INFO] |&amp;nbsp; +- org.apache.camel:camel-core-engine:jar:3.1.0-SNAPSHOT:compile&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: Courier New, Courier, monospace; font-size: x-small;"&gt;&lt;b&gt;[INFO] |&amp;nbsp; +- org.apache.camel:camel-management-api:jar:3.1.0-SNAPSHOT:compile&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: Courier New, Courier, monospace; font-size: x-small;"&gt;&lt;b&gt;[INFO] |&amp;nbsp; +- org.apache.camel:camel-support:jar:3.1.0-SNAPSHOT:compile&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: Courier New, Courier, monospace; font-size: x-small;"&gt;&lt;b&gt;[INFO] |&amp;nbsp; \- org.apache.camel:camel-util:jar:3.1.0-SNAPSHOT:compile&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: Courier New, Courier, monospace; font-size: x-small;"&gt;&lt;b&gt;[INFO] +- org.apache.camel:camel-bean:jar:3.1.0-SNAPSHOT:compile&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: Courier New, Courier, monospace; font-size: x-small;"&gt;&lt;b&gt;[INFO] +- org.apache.camel:camel-timer:jar:3.1.0-SNAPSHOT:compile&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: Courier New, Courier, monospace; font-size: x-small;"&gt;[INFO] +- org.apache.logging.log4j:log4j-api:jar:2.13.0:compile&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: Courier New, Courier, monospace; font-size: x-small;"&gt;[INFO] +- ch.qos.logback:logback-core:jar:1.2.3:compile&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: Courier New, Courier, monospace; font-size: x-small;"&gt;[INFO] \- ch.qos.logback:logback-classic:jar:1.2.3:compile&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: Courier New, Courier, monospace; font-size: x-small;"&gt;[INFO]&amp;nbsp; &amp;nbsp; \- org.slf4j:slf4j-api:jar:1.7.30:compile&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: Courier New, Courier, monospace; font-size: x-small;"&gt;&lt;br /&gt;&lt;/span&gt;I ran this example with the profiler and configured it to use 10MB as max heap (-Xmx10M) and as the summary shows this can easily be done. About 5mb is used in the heap.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-ps-KFiZPWX8/XkQFccKVD0I/AAAAAAAACFE/ow6g11f_y-MwkZlVJihHOy9lGsAJsnOAQCLcBGAsYHQ/s1600/10mb-heap.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="378" data-original-width="959" height="156" src="https://1.bp.blogspot.com/-ps-KFiZPWX8/XkQFccKVD0I/AAAAAAAACFE/ow6g11f_y-MwkZlVJihHOy9lGsAJsnOAQCLcBGAsYHQ/s400/10mb-heap.png" width="400" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;There has also been a few other minor improvements to avoid using Camel 2.x based type converter scanning by default. This reduces a scan on the classpath.&lt;br /&gt;&lt;br /&gt;Okay its time to end this blog series and finish up the last bits so we can get Camel 3.1 released.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=pDnbDdBSPvk:BQL4WkBoZ80:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=pDnbDdBSPvk:BQL4WkBoZ80:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=pDnbDdBSPvk:BQL4WkBoZ80:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=pDnbDdBSPvk:BQL4WkBoZ80:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=pDnbDdBSPvk:BQL4WkBoZ80:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=pDnbDdBSPvk:BQL4WkBoZ80:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=pDnbDdBSPvk:BQL4WkBoZ80:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/ApacheCamel/~4/pDnbDdBSPvk" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/d_w0EQzcH50" height="1" width="1" alt=""/&gt;</content><summary>I have previously blogged about the optimizations we are doing in the next Camel 3.1 release blog part 1 blog part 2 Today I wanted to give a short update on the latest development we have done, as we are closing down on being ready to build and release Camel 3.1 as early as end of this week or the following. Since part 2, we managed to find additional 10% reduction on object allocations during ro...</summary><dc:creator>Claus Ibsen</dc:creator><dc:date>2020-02-12T14:05:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/pDnbDdBSPvk/apache-camel-31-more-camel-core.html</feedburner:origLink></entry><entry><title>Podman for macOS (sort of)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/eMddeLOEPTw/" /><category term="Containers" /><category term="Operating System" /><category term="buildah" /><category term="os x" /><category term="Podman" /><category term="skopeo" /><author><name>Rarm Nagalingam</name></author><id>https://developers.redhat.com/blog/?p=675017</id><updated>2020-02-12T08:00:21Z</updated><published>2020-02-12T08:00:21Z</published><content type="html">&lt;p&gt;I have a problem. My daily laptop is a MacBook Pro, which is great unless you want to dual boot into Linux and develop on containers. While it is simple enough to install &lt;a href="https://developers.redhat.com/products/codeready-containers/overview" target="_blank" rel="noopener noreferrer"&gt;Red Hat CodeReady Containers&lt;/a&gt;, what I really needed was a way to run Buildah, Podman, and skopeo on macOS without having to water and feed a Linux VM.&lt;/p&gt; &lt;p&gt;Look no further: Podman-machine has somewhat solved this problem.&lt;/p&gt; &lt;h2&gt;Podman-machine&lt;/h2&gt; &lt;p&gt;Podman-machine starts a virtual machine that already streamlines the Podman, Buildah, and skopeo packages. The developers released two VM flavors: an in-memory Tiny Core and a Fedora version.&lt;/p&gt; &lt;p&gt;You have the option of compiling additional driver support for hypervisors like xhyve, but I would recommend VirtualBox as it seems to work more smoothly.&lt;/p&gt; &lt;h2&gt;Getting started&lt;/h2&gt; &lt;p&gt;My instructions are based on &lt;a href="https://github.com/boot2podman/machine" target="_blank" rel="noopener noreferrer"&gt;the official ones here&lt;/a&gt;. The guide also assumes you have VirtualBox already installed.&lt;/p&gt; &lt;p&gt;Start by downloading the latest &lt;code&gt;podman-machine&lt;/code&gt; binary. At the time of this writing, the latest release was v0.16:&lt;/p&gt; &lt;pre&gt;$ curl -L https://github.com/boot2podman/machine/releases/download/v0.16/podman-machine.darwin-amd64 --output /usr/local/bin/podman-machine chmod +x &lt;/pre&gt; &lt;h3&gt;Setting up your VM&lt;/h3&gt; &lt;p&gt;Then, create a &lt;code&gt;boot2podman&lt;/code&gt; VM. I am using a Fedora 31 virtual machine with 4GB of RAM, and I attached my local &lt;code&gt;~/Code&lt;/code&gt; directory to this VM.&lt;/p&gt; &lt;p&gt;I updated the image to Fedora 31 and allowed rootless image building. The image should make it &lt;a href="https://github.com/boot2podman/boot2podman-fedora-iso" target="_blank" rel="noopener noreferrer"&gt;to the official repo&lt;/a&gt;. In the meantime, I referenced the development release below:&lt;/p&gt; &lt;pre&gt;$ podman-machine create --virtualbox-boot2podman-url https://github.com/snowjet/boot2podman-fedora-iso/releases/download/d1bb19f/boot2podman-fedora.iso --virtualbox-memory="4096" --virtualbox-share-folder ~/Code:code fedbox &lt;/pre&gt; &lt;p&gt;You now have a VM with a persistent disk for container images, but it runs the OS in memory. You can log into the VM and view your shared directory at &lt;code&gt;/sf_code&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;$ podman-machine ssh fedbox ls /sf_code total 12 drwxrwx---. 1 root vboxsf 128 Jan 13 21:15 . dr-xr-xr-x. 18 root root 4096 Jan 14 22:42 .. drwxrwx---. 1 root vboxsf 480 Aug 28 05:40 container-proj &lt;/pre&gt; &lt;h3&gt;Setting up your container&lt;/h3&gt; &lt;p&gt;Now, let&amp;#8217;s run a container and communicate with it:&lt;/p&gt; &lt;pre&gt;$ podman-machine ssh fedbox $ podman run -p 8080:80/tcp --rm httpd Trying to pull docker.io/library/httpd... Getting image source signatures Copying blob 27298e4c749a done Copying blob 354e6904d655 done Copying blob 36412f6b2f6e done Copying blob 10e27104ba69 done Copying blob 8ec398bc0356 [======================================] 25.8MiB / 25.8MiB Copying config c2aa7e16ed [======================================] 7.2KiB / 7.2KiB Writing manifest to image destination Storing signatures ... [Thu Jan 16 01:28:19.051375 2020] [core:notice] [pid 1:tid 140000832345216] AH00094: Command line: 'httpd -D FOREGROUND' &lt;/pre&gt; &lt;p&gt;In another terminal, run:&lt;/p&gt; &lt;pre&gt;$ podman-machine ip fedbox 192.168.99.122 $ curl http://192.168.99.122:8080 It works! &lt;/pre&gt; &lt;p&gt;Finally, you can create containers on your Mac and communicate with them.&lt;/p&gt; &lt;h3&gt;Closing your workspace&lt;/h3&gt; &lt;p&gt;To stop and clean up your workspace, run:&lt;/p&gt; &lt;pre&gt;$ podman-machine stop fedbox $ podman-machine rm fedbox &lt;/pre&gt; &lt;p&gt;Now you can easily build, run, and push containers from your Mac.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F12%2Fpodman-for-macos-sort-of%2F&amp;#38;linkname=Podman%20for%20macOS%20%28sort%20of%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F12%2Fpodman-for-macos-sort-of%2F&amp;#38;linkname=Podman%20for%20macOS%20%28sort%20of%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F12%2Fpodman-for-macos-sort-of%2F&amp;#38;linkname=Podman%20for%20macOS%20%28sort%20of%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F12%2Fpodman-for-macos-sort-of%2F&amp;#38;linkname=Podman%20for%20macOS%20%28sort%20of%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F12%2Fpodman-for-macos-sort-of%2F&amp;#38;linkname=Podman%20for%20macOS%20%28sort%20of%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F12%2Fpodman-for-macos-sort-of%2F&amp;#38;linkname=Podman%20for%20macOS%20%28sort%20of%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F12%2Fpodman-for-macos-sort-of%2F&amp;#38;linkname=Podman%20for%20macOS%20%28sort%20of%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F12%2Fpodman-for-macos-sort-of%2F&amp;#038;title=Podman%20for%20macOS%20%28sort%20of%29" data-a2a-url="https://developers.redhat.com/blog/2020/02/12/podman-for-macos-sort-of/" data-a2a-title="Podman for macOS (sort of)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/12/podman-for-macos-sort-of/"&gt;Podman for macOS (sort of)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/eMddeLOEPTw" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;I have a problem. My daily laptop is a MacBook Pro, which is great unless you want to dual boot into Linux and develop on containers. While it is simple enough to install Red Hat CodeReady Containers, what I really needed was a way to run Buildah, Podman, and skopeo on macOS without having to [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/12/podman-for-macos-sort-of/"&gt;Podman for macOS (sort of)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">675017</post-id><dc:creator>Rarm Nagalingam</dc:creator><dc:date>2020-02-12T08:00:21Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/02/12/podman-for-macos-sort-of/</feedburner:origLink></entry><entry><title>Toward _FORTIFY_SOURCE parity between Clang and GCC</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/GVirXANEwCc/" /><category term="C" /><category term="C++" /><category term="clang/LLVM" /><category term="_FORTIFY_SOURCE" /><category term="buffer overflow" /><category term="compatibility" /><category term="gcc" /><category term="glibc" /><author><name>Serge Guelton</name></author><id>https://developers.redhat.com/blog/?p=673947</id><updated>2020-02-11T08:00:39Z</updated><published>2020-02-11T08:00:39Z</published><content type="html">&lt;p&gt;GCC combined with glibc can detect instances of buffer overflow by standard C library functions. When a user passes the &lt;code&gt;-D_FORTIFY_SOURCE={1,2}&lt;/code&gt; &lt;em&gt;preprocessor&lt;/em&gt; flag and an optimization level greater or equal to &lt;code&gt;-O1&lt;/code&gt;, an alternate, &lt;em&gt;fortified&lt;/em&gt; implementation of the function is used when calling, say, &lt;code&gt;strcpy&lt;/code&gt;. Depending on the function and its inputs, this behavior may result in a compile-time error, or a runtime error triggered upon execution. (For more info on this feature, there&amp;#8217;s an &lt;a href="https://access.redhat.com/blogs/766093/posts/1976213" target="_blank" rel="noopener noreferrer"&gt;excellent blog post here&lt;/a&gt; on the subject).&lt;/p&gt; &lt;p&gt;What about the Clang plus glibc duo? This article digs through &lt;code&gt;-D_FORTIFY_SOURCE&lt;/code&gt; usage and discuss the patches applied to Clang to achieve feature parity.&lt;/p&gt; &lt;h1&gt;First glance&lt;/h1&gt; &lt;p&gt;Let&amp;#8217;s look at &lt;code&gt;-D_FORTIFY_SOURCE&lt;/code&gt; through the compiler portability prism. As this feature relies on a preprocessor definition, it should only involve preprocessor selection. Compatibility should come for free, right?&lt;/p&gt; &lt;p&gt;Not quite. Following the definitions in the &lt;code&gt;glibc&lt;/code&gt; headers, one quickly spots compiler-specific function calls that are relied on to implement the security check. A &lt;a href="https://gatherer.wizards.com/Pages/Card/Details.aspx?multiverseid=29727" target="_blank" rel="noopener noreferrer"&gt;careful study&lt;/a&gt; of the headers leads to the following builtins being used at some point in the headers, included solely when &lt;code&gt;-D_FORTIFY_SOURCE&lt;/code&gt; is on:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;__builtin_constant_p&lt;/li&gt; &lt;li&gt;__builtin_object_size&lt;/li&gt; &lt;li&gt;__builtin___memcpy_chk&lt;/li&gt; &lt;li&gt;__builtin___memmove_chk&lt;/li&gt; &lt;li&gt;__builtin___mempcpy_chk&lt;/li&gt; &lt;li&gt;__builtin___memset_chk&lt;/li&gt; &lt;li&gt;__builtin___snprintf_chk&lt;/li&gt; &lt;li&gt;__builtin___sprintf_chk&lt;/li&gt; &lt;li&gt;__builtin___stpcpy_chk&lt;/li&gt; &lt;li&gt;__builtin___strcat_chk&lt;/li&gt; &lt;li&gt;__builtin___strcpy_chk&lt;/li&gt; &lt;li&gt;__builtin___strncat_chk&lt;/li&gt; &lt;li&gt;__builtin___strncpy_chk&lt;/li&gt; &lt;li&gt;__builtin___vsnprintf_chk&lt;/li&gt; &lt;li&gt;__builtin___vsprintf_chk&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Those are the compiler &lt;em&gt;builtins&lt;/em&gt;, as hinted by the &lt;code&gt;__builtin__&lt;/code&gt; prefix, which means that either the compiler knows them and provides its own implementation/handling, or the compilation (or linking) process will fail. So in order to support &lt;code&gt;-D_FORTIFY_SOURCE&lt;/code&gt;, a compiler must support these builtins. All of them (except &lt;code&gt;__builtin_constant_p&lt;/code&gt; and &lt;code&gt;__builtin_object_size&lt;/code&gt;) are suffixed by &lt;code&gt;_chk&lt;/code&gt;, which suggests they are hardened versions of the corresponding function from libc.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s take a deeper look at these functions.&lt;/p&gt; &lt;h1&gt;Required compiler builtins&lt;/h1&gt; &lt;p&gt;The following compiler builtins are required for &lt;code&gt;-D_FORTIFY_SOURCE&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;&lt;code&gt;__builtin_object_size(obj, type)&lt;/code&gt;&lt;/h3&gt; &lt;p&gt;This builtin function is complex. The interested reader may want to check out its &lt;a href="https://gcc.gnu.org/onlinedocs/gcc/Object-Size-Checking.html" target="_blank" rel="noopener noreferrer"&gt;online documentation&lt;/a&gt;. As a short summary, let&amp;#8217;s assume that this function tries to compute the allocated size of &lt;code&gt;obj&lt;/code&gt; at compile time, and then returns it. If this process fails, it returns &lt;code&gt;-1&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;type&lt;/code&gt; argument controls details of this function&amp;#8217;s semantics. The following definition is made available in &lt;code&gt;cdefs.h&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;#define __bos(ptr) __builtin_object_size (ptr, __USE_FORTIFY_LEVEL &amp;#62; 1)&lt;/pre&gt; &lt;h3&gt;&lt;code&gt;__builtin_constant_p(obj)&lt;/code&gt;&lt;/h3&gt; &lt;p&gt;This function returns &lt;code&gt;1&lt;/code&gt; if the value of &lt;code&gt;obj&lt;/code&gt; is known at compile time (after optimizations) and returns &lt;code&gt;0&lt;/code&gt; otherwise. The following code, extracted from &lt;code&gt;stdio2.h&lt;/code&gt; in the &lt;code&gt;glibc&lt;/code&gt; version 2.30, showcases an example of usage:&lt;/p&gt; &lt;pre&gt;__fortify_function __wur char * fgets (char *__restrict __s, int __n, FILE *__restrict __stream) { if (__bos (__s) != (size_t) -1) { if (!__builtin_constant_p (__n) || __n &amp;#60;= 0) return __fgets_chk (__s, __bos (__s), __n, __stream); if ((size_t) __n &amp;#62; __bos (__s)) return __fgets_chk_warn (__s, __bos (__s), __n, __stream); } return __fgets_alias (__s, __n, __stream); } //* &lt;/pre&gt; &lt;p&gt;This code reads as:&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;If we can compute the basic object size (bos) of the first parameter of &lt;code&gt;fgets&lt;/code&gt;, then if the second parameter is not known at compile time, use the &lt;code&gt;__fgets_chk&lt;/code&gt; function. If the second parameter is greater than the object size, then use &lt;code&gt;__fgets_chk_warn&lt;/code&gt;. Otherwise, we know (at compile time) that the call is secure and the original function is called through &lt;code&gt;__fgets_alias&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;&lt;code&gt;__builtin___memcpy_chk(dest, src, n, dest_size)&lt;/code&gt;&lt;/h3&gt; &lt;p&gt;The extra &lt;code&gt;dest_size&lt;/code&gt; argument is used for comparison with &lt;code&gt;n&lt;/code&gt;. &lt;code&gt;dest_size&lt;/code&gt; can be &lt;code&gt;-1&lt;/code&gt;, which means its value is unknown at compile time. It can have a positive value, in which case it means that &amp;#8220;the number of allocated bytes remaining after the location pointed by &lt;code&gt;dest&lt;/code&gt; is &lt;code&gt;dest_size&lt;/code&gt;.&amp;#8221; When &lt;code&gt;dest_size&lt;/code&gt;is positive and lower than &lt;code&gt;n&lt;/code&gt;, an error is emitted either at compile time or at runtime.&lt;/p&gt; &lt;p&gt;The other &lt;code&gt;__bultin__*_chk&lt;/code&gt; builtins do similar checks based on the destination buffer&amp;#8217;s compiler-computed object size and the actual copy size.&lt;/p&gt; &lt;h1&gt;Clang compatibility&lt;/h1&gt; &lt;p&gt;After a quick check of the builtins supported by Clang, it turns out that all the builtins required by &lt;code&gt;-D_FORTIFY_SOURCE=2&lt;/code&gt; are supported by Clang. That&amp;#8217;s a nice property: It means that you can pass that pre-processor flag to Clang when compiling your C (or C++) application and it compiles just fine. As a matter of fact, Firefox already &lt;a href="https://searchfox.org/mozilla-central/source/build/moz.configure/toolchain.configure#1540-1551" target="_blank" rel="noopener noreferrer"&gt;builds with Clang and that flag&lt;/a&gt;, so it indeed &lt;em&gt;compiles&lt;/em&gt; fine.&lt;/p&gt; &lt;p&gt;But do we get the extra protection? After a deeper look at Clang&amp;#8217;s source code, the answer is more nuanced. Based on the body of &lt;code&gt;&lt;a href="https://github.com/llvm/llvm-project/blob/release/9.x/clang/lib/Sema/SemaChecking.cpp#L315" target="_blank" rel="noopener noreferrer"&gt;Sema::checkFortifiedBuiltinMemoryFunction&lt;/a&gt;&lt;/code&gt;, the check is only performed if both the size argument and the object size are known at compile time. Otherwise, no checks are performed. This sequence is different from the GCC behavior, where a call to &lt;code&gt;__memcpy_chk&lt;/code&gt; is generated in that case.&lt;/p&gt; &lt;p&gt;A look at &lt;a href="https://godbolt.org/z/xXfpNZ" target="_blank" rel="noopener noreferrer"&gt;this snippet&lt;/a&gt; illustrates GCC&amp;#8217;s behavior. The size argument of the &lt;code&gt;memcpy&lt;/code&gt; call is a runtime value, but both the destination and the source argument have a size known at compile time. GCC internal representation shows a call to &lt;code&gt;__builtin___memcpy_chk&lt;/code&gt; lowered to &lt;code&gt;__memcpy_chk&lt;/code&gt;. On the other hand, Clang just &lt;a href="https://godbolt.org/z/TBDbY6" target="_blank" rel="noopener noreferrer"&gt;issues a regular call to &lt;code&gt;memcpy&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;h1&gt;Patching Clang&lt;/h1&gt; &lt;p&gt;Digging into Clang&amp;#8217;s code reveals that whenever it meets a call to &lt;code&gt;memcpy&lt;/code&gt;, the call is replaced by a call to &lt;a href="http://llvm.org/docs/LangRef.html#llvm-memcpy-intrinsic" target="_blank" rel="noopener noreferrer"&gt;LLVM&amp;#8217;s builtin &lt;code&gt;llvm.memcpy&lt;/code&gt;&lt;/a&gt;. Unfortunately, what &lt;code&gt;-D_FORTIFY_SOURCE={1,2}&lt;/code&gt; does is unguard an inline definition of &lt;code&gt;memcpy&lt;/code&gt; with the fortified implementation. And that&amp;#8217;s the implementation Clang should use. This &lt;a href="https://reviews.llvm.org/D71082" target="_blank" rel="noopener noreferrer"&gt;patch&lt;/a&gt; implements this extra behavior, with the mandatory extra tests.&lt;/p&gt; &lt;p&gt;To validate the whole approach, I wrote a &lt;a href="https://github.com/serge-sans-paille/fortify-test-suite/" target="_blank" rel="noopener noreferrer"&gt;minimal test suite&lt;/a&gt; for fortifying compilers. GCC passes it &lt;em&gt;by design&lt;/em&gt;, and Clang 9 doesn&amp;#8217;t. However, using the top-of-tree version of Clang (&lt;code&gt;346de9b6&lt;/code&gt; as of this writing), the test suite now passes just fine:&lt;/p&gt; &lt;pre&gt;(sh) make check-gcc [...] ===== GCC OK ===== (sh) PATH=/path/to/clang:$PATH make check-clang [...] ===== CLANG OK ===== &lt;/pre&gt; &lt;h1&gt;Conclusion&lt;/h1&gt; &lt;p&gt;When aiming at feature parity, the devil is in the details. In the case of &lt;code&gt;-D_FORTIFY_SOURCE&lt;/code&gt;, Clang seemingly supported the feature. We are now one step further toward feature parity.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F11%2Ftoward-_fortify_source-parity-between-clang-and-gcc%2F&amp;#38;linkname=Toward%20_FORTIFY_SOURCE%20parity%20between%20Clang%20and%20GCC" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F11%2Ftoward-_fortify_source-parity-between-clang-and-gcc%2F&amp;#38;linkname=Toward%20_FORTIFY_SOURCE%20parity%20between%20Clang%20and%20GCC" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F11%2Ftoward-_fortify_source-parity-between-clang-and-gcc%2F&amp;#38;linkname=Toward%20_FORTIFY_SOURCE%20parity%20between%20Clang%20and%20GCC" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F11%2Ftoward-_fortify_source-parity-between-clang-and-gcc%2F&amp;#38;linkname=Toward%20_FORTIFY_SOURCE%20parity%20between%20Clang%20and%20GCC" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F11%2Ftoward-_fortify_source-parity-between-clang-and-gcc%2F&amp;#38;linkname=Toward%20_FORTIFY_SOURCE%20parity%20between%20Clang%20and%20GCC" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F11%2Ftoward-_fortify_source-parity-between-clang-and-gcc%2F&amp;#38;linkname=Toward%20_FORTIFY_SOURCE%20parity%20between%20Clang%20and%20GCC" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F11%2Ftoward-_fortify_source-parity-between-clang-and-gcc%2F&amp;#38;linkname=Toward%20_FORTIFY_SOURCE%20parity%20between%20Clang%20and%20GCC" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F11%2Ftoward-_fortify_source-parity-between-clang-and-gcc%2F&amp;#038;title=Toward%20_FORTIFY_SOURCE%20parity%20between%20Clang%20and%20GCC" data-a2a-url="https://developers.redhat.com/blog/2020/02/11/toward-_fortify_source-parity-between-clang-and-gcc/" data-a2a-title="Toward _FORTIFY_SOURCE parity between Clang and GCC"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/11/toward-_fortify_source-parity-between-clang-and-gcc/"&gt;Toward _FORTIFY_SOURCE parity between Clang and GCC&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/GVirXANEwCc" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;GCC combined with glibc can detect instances of buffer overflow by standard C library functions. When a user passes the -D_FORTIFY_SOURCE={1,2} preprocessor flag and an optimization level greater or equal to -O1, an alternate, fortified implementation of the function is used when calling, say, strcpy. Depending on the function and its inputs, this behavior may result [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/11/toward-_fortify_source-parity-between-clang-and-gcc/"&gt;Toward _FORTIFY_SOURCE parity between Clang and GCC&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">673947</post-id><dc:creator>Serge Guelton</dc:creator><dc:date>2020-02-11T08:00:39Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/02/11/toward-_fortify_source-parity-between-clang-and-gcc/</feedburner:origLink></entry><entry><title>Installing Kubeflow v0.7 on OpenShift 4.2</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/KDXuwXzLVJc/" /><category term="Containers" /><category term="Kubernetes" /><category term="Service Mesh" /><category term="CodeReady Containers" /><category term="istio" /><category term="Kubeflow" /><category term="Open Data Hub" /><category term="openshift" /><author><name>Juana Nakfour</name></author><id>https://developers.redhat.com/blog/?p=679917</id><updated>2020-02-10T08:00:14Z</updated><published>2020-02-10T08:00:14Z</published><content type="html">&lt;p&gt;As part of the &lt;a href="http://opendatahub.io/" target="_blank" rel="noopener noreferrer"&gt;Open Data Hub&lt;/a&gt; project, we see potential and value in the Kubeflow project, so we dedicated our efforts to enable Kubeflow on &lt;a href="http://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt;. We decided to use Kubeflow 0.7 as that was the latest released version at the time this work began. The work included adding new installation scripts that provide all of the necessary changes such as permissions for service accounts to run on OpenShift.&lt;/p&gt; &lt;p&gt;The installation of Kubeflow is limited to the following components:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Central dashboard&lt;/li&gt; &lt;li&gt;Jupyterhub&lt;/li&gt; &lt;li&gt;Katib&lt;/li&gt; &lt;li&gt;Pipelines&lt;/li&gt; &lt;li&gt;Pytorch, tf-jobs (training)&lt;/li&gt; &lt;li&gt;Seldon (serving)&lt;/li&gt; &lt;li&gt;Istio&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;All of the new fixes and features will be proposed upstream to the Kubeflow project in the near future.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;To install Kubeflow on OpenShift, there are prerequisites regarding the platform and the tools.&lt;/p&gt; &lt;h3&gt;Platform&lt;/h3&gt; &lt;p&gt;To run this installation, OpenShift is needed as a platform. You can use either OpenShift 4.2 or &lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;Red Hat CodeReady Containers&lt;/a&gt; (CRC). If you choose OpenShift 4.2, all that you need is an available OpenShift 4.2 cluster. Or, you can try a cluster on &lt;a href="https://try.openshift.com/" target="_blank" rel="noopener noreferrer"&gt;try.openshift.com&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;If you choose CodeReady Containers, you need a CRC-generated OpenShift cluster. Here are the recommended specifications:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;16GB RAM&lt;/li&gt; &lt;li&gt;6 CPUs&lt;/li&gt; &lt;li&gt;45GB disk space&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The minimum specifications are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;10GB RAM&lt;/li&gt; &lt;li&gt;6 CPUs&lt;/li&gt; &lt;li&gt;30GB disk space (the default for CRC)&lt;/li&gt; &lt;/ul&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: At the minimum specs, the CRC OpenShift cluster might be unresponsive for approximately 20 minutes while the Kubeflow components are being deployed.&lt;/p&gt; &lt;p&gt;When installing Kubeflow on a CRC cluster, there is an extra overlay (named &amp;#8220;crc&amp;#8221;) to enable the metadata component in &lt;code&gt;kfctl_openshift.yaml&lt;/code&gt;. This overlay is commented out by default. Uncomment the overlay to enable it.&lt;/p&gt; &lt;h3&gt;Tools&lt;/h3&gt; &lt;p&gt;The installation tool &lt;code&gt;kfctl&lt;/code&gt; is needed to install/uninstall Kubeflow. Download the tool from &lt;a href="https://github.com/kubeflow/kubeflow/releases/" target="_blank" rel="noopener noreferrer"&gt;GitHub&lt;/a&gt;. Version 0.7.0 is required for this installation.&lt;/p&gt; &lt;h2&gt;Installing Kubeflow with Istio enabled&lt;/h2&gt; &lt;p&gt;As noted earlier, we added a KFDef file to specifically install Kubeflow on OpenShift and included fixes for different components. To install Kubeflow 0.7 on OpenShift 4.2 please follow the steps below. It is assumed that this installation will run on an OpenShift 4.2 cluster:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Clone the &lt;code&gt;opendatahub-manifest&lt;/code&gt; fork repo, which defaults to the branch &lt;code&gt;v0.7.0-branch-openshift&lt;/code&gt;:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;$ git clone https://github.com/opendatahub-io/manifests.git $ cd manifests&lt;/pre&gt; &lt;ol start="2"&gt; &lt;li&gt;Install using the OpenShift configuration file and the locally downloaded manifests, since at the time of writing we ran into this Kubeflow &lt;a href="https://github.com/kubeflow/kubeflow/issues/4678" target="_blank" rel="noopener noreferrer"&gt;bug&lt;/a&gt; that would not allow downloading the manifests during a build process:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;$ sed -i 's#uri: .*#uri: '$PWD'#' ./kfdef/kfctl_openshift.yaml $ kfctl build --file=kfdef/kfctl_openshift.yaml $ kfctl apply --file=./kfdef/kfctl_openshift.yaml&lt;/pre&gt; &lt;ol start="3"&gt; &lt;li&gt;Verify your installation:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;$ oc get pods&lt;/pre&gt; &lt;ol start="4"&gt; &lt;li&gt;Launch the Kubeflow portal:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;$ oc get routes -n istio-system istio-ingressgateway -o jsonpath='http://{.spec.host}/' http://&amp;#60;istio ingress route&amp;#62;/&lt;/pre&gt; &lt;h2&gt;Deleting a Kubeflow installation&lt;/h2&gt; &lt;p&gt;To delete a Kubeflow installation, follow these steps:&lt;/p&gt; &lt;pre&gt;$ kfctl delete --file=./kfdef/&amp;#60;kfctl file name&amp;#62;.yaml $ rm -rf kfdef/kustomize/ $ oc delete mutatingwebhookconfigurations.admissionregistration.k8s.io --all $ oc delete validatingwebhookconfigurations.admissionregistration.k8s.io --all $ oc delete namespace istio-system&lt;/pre&gt; &lt;h2&gt;Kubeflow components&lt;/h2&gt; &lt;p&gt;To enable the installation of Kubeflow 0.7 on OpenShift 4.2, we added features and fixes to alleviate the installation issues we encountered. The following is a list of components along with a description of the changes and usage examples.&lt;/p&gt; &lt;h3&gt;OpenShift KFDef&lt;/h3&gt; &lt;p&gt;KFDef is a specification designed to control the provisioning and management of Kubeflow deployment. This spec is generally distributed in YAML format and follows a pattern of custom resources popular in Kubernetes to extend the platform. With the upcoming addition of Kubeflow Operator, KFDef is becoming the custom resource used for Kubeflow deployment and lifecycle management.&lt;/p&gt; &lt;p&gt;KFDef is built on top of &lt;a href="https://kustomize.io/" target="_blank" rel="noopener noreferrer"&gt;Kustomize&lt;/a&gt;, which is a Kubernetes-native configuration management system. To deploy Kubeflow to OpenShift, we had to create a new KFDef YAML file that customizes the deployment manifests of Kubeflow components for OpenShift. With Kustomize as a configuration management layer for every component, it was necessary to add OpenShift-specific Kustomize overlays (patches applied to the default set of resource manifests when an overlay is selected).&lt;/p&gt; &lt;p&gt;Take a look at the OpenShift-specific KFDef file used in the deployment steps above in the &lt;a href="https://github.com/opendatahub-io/manifests/blob/v0.7-branch-openshift/kfdef/kfctl_openshift.yaml" target="_blank" rel="noopener noreferrer"&gt;opendatahub-io/manifests&lt;/a&gt; repository.&lt;/p&gt; &lt;h3&gt;Central dashboard&lt;/h3&gt; &lt;p&gt;The central dashboard works out of the box, provided that you access the Kubeflow web UI using the route for &lt;code&gt;istio-ingressgateway&lt;/code&gt; in the &lt;code&gt;istio-system&lt;/code&gt; namespace.&lt;/p&gt; &lt;p&gt;Upon first accessing the web UI, you will be prompted to create a Kubeflow user namespace. This is a one-time action for creating a single namespace. If you want to make additional namespaces accessible for Kubeflow deployment of notebook servers, Pipelines, etc., you can create a Kubeflow &lt;a href="https://www.kubeflow.org/docs/other-guides/multi-user-overview/#manual-profile-creation" target="_blank" rel="noopener noreferrer"&gt;profile&lt;/a&gt;. By default, the central dashboard does not have authentication enabled.&lt;/p&gt; &lt;h3&gt;Jupyter controller&lt;/h3&gt; &lt;p&gt;We are using three Jupyter controller customizations: a custom notebook controller, a custom profile controller, and a custom notebook image. Let&amp;#8217;s take a look at each.&lt;/p&gt; &lt;h4&gt;Custom notebook controller&lt;/h4&gt; &lt;p&gt;We are using a customized notebook controller to avoid the default behavior of setting &lt;code&gt;fsGroup: 100&lt;/code&gt; in the stateful set that is created when spawning a notebook. That value would require a special security context restraint (SCC) for the service account in OpenShift. To further complicate matters, that SCC would need to be granted to a service account that is created only when the profile is created, so it’s not something that can be done during installation.&lt;/p&gt; &lt;p&gt;Related links:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://github.com/kubeflow/kubeflow/issues/4617" target="_blank" rel="noopener noreferrer"&gt;The related upstream issue&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="http://quay.io/kubeflow/notebook-controller:v0.7.0" target="_blank" rel="noopener noreferrer"&gt;The repository for this controller image&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/crobby/kubeflow/tree/openshift-fixes" target="_blank" rel="noopener noreferrer"&gt;The source is here&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h4&gt;Custom profile controller&lt;/h4&gt; &lt;p&gt;We are using a customized profile controller to avoid the default behavior of newly created profiles having the label &lt;code&gt;istio-injection: enabled&lt;/code&gt;. That label causes the container to attempt to start an &lt;code&gt;istio-init&lt;/code&gt; container that, in turn, tries to use &lt;code&gt;iptables&lt;/code&gt;, which is not available in OpenShift 4.x. That init container will fail and cause the notebook start to fail.&lt;/p&gt; &lt;p&gt;Related links:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://github.com/kubeflow/kubeflow/issues/4566" target="_blank" rel="noopener noreferrer"&gt;The related upstream issue&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://quay.io/repository/kubeflow/profile-controller?tag=v0.7.0&amp;#38;tab=tags" target="_blank" rel="noopener noreferrer"&gt;The repository for the controller image&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/crobby/kubeflow/tree/openshift-fixes" target="_blank" rel="noopener noreferrer"&gt;The source is here&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h4&gt;Custom notebook image&lt;/h4&gt; &lt;p&gt;We also added our own &lt;a href="http://quay.io/kubeflow/tf-notebook-image" target="_blank" rel="noopener noreferrer"&gt;custom notebook image&lt;/a&gt;, which is prepopulated in the image selection dropdown. This image provides filesystem permissions in the &lt;code&gt;/home/jovyan&lt;/code&gt; directory. It offers &lt;a href="https://github.com/kubeflow/kubeflow/pull/4537" target="_blank" rel="noopener noreferrer"&gt;the functionality described here&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Katib&lt;/h3&gt; &lt;p&gt;Katib suffered two main problems. The first was not being able to run cleanly as an unprivileged user (&lt;a href="https://github.com/kubeflow/katib/pull/960" target="_blank" rel="noopener noreferrer"&gt;#960&lt;/a&gt;, &lt;a href="https://github.com/kubeflow/katib/pull/962" target="_blank" rel="noopener noreferrer"&gt;#962&lt;/a&gt;, &lt;a href="https://github.com/kubeflow/katib/pull/967" target="_blank" rel="noopener noreferrer"&gt;#967&lt;/a&gt;). The second is that it was damaging a generated security context in a pod by mutating the pod (&lt;a href="https://github.com/kubeflow/katib/pull/964" target="_blank" rel="noopener noreferrer"&gt;#964&lt;/a&gt;). Both have been fixed in upstream Katib repositories and Katib now runs without issues on OpenShift.&lt;/p&gt; &lt;p&gt;The second &lt;a href="https://github.com/kubeflow/katib/pull/964" target="_blank" rel="noopener noreferrer"&gt;issue&lt;/a&gt;, in particular, is a pattern common in applications relying on mutating webhooks where part of the mutation is adding a sidecar container to the pod that is being deployed. If the new container does not have an initialized security context, the pod admission policy controller will prevent its deployment. We have seen the same issue in the &lt;a href="https://github.com/kubeflow/kfserving/pull/613" target="_blank" rel="noopener noreferrer"&gt;KFServing component&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Pipelines&lt;/h3&gt; &lt;p&gt;To get Kubeflow Pipelines working on OpenShift, we had to specify the &lt;code&gt;k8sapi&lt;/code&gt; executor for Argo because OpenShift 4.2 does not include a Docker daemon and CLI. Instead, it uses &lt;a href="https://www.redhat.com/en/blog/red-hat-openshift-container-platform-4-now-defaults-cri-o-underlying-container-engine" target="_blank" rel="noopener noreferrer"&gt;CRI-O&lt;/a&gt; as the container engine by default. We also had to add the finalizers to the workflow permissions for OpenShift to be able to set owner references.&lt;/p&gt; &lt;p&gt;This practice allows running YAML-based Pipelines that conform to Argo’s specification regarding &lt;code&gt;k8sapi&lt;/code&gt; Pipelines execution, specifically for the condition of saving params and artifacts in volumes (such as &lt;code&gt;emtpyDir&lt;/code&gt;) and not the path that is part of the base image layer (for example, &lt;code&gt;/tmp&lt;/code&gt;). This specific requirement rendered all example Kubeflow Python Pipelines with errors. To test your Pipelines, use the fraud detection Pipelines provided in &lt;a href="https://developers.redhat.com/blog/2019/12/16/ai-ml-pipelines-using-open-data-hub-and-kubeflow-on-red-hat-openshift/"&gt;this article&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;For &lt;code&gt;minio&lt;/code&gt; installation, we also created a service account and gave that account permission to run as &lt;code&gt;anyuid&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Training&lt;/h3&gt; &lt;p&gt;For training, we had to make changes for two of the apps: PyTorch and TensorFlow jobs (tf-jobs).&lt;/p&gt; &lt;h4&gt;PyTorch&lt;/h4&gt; &lt;p&gt;For PyTorch, we did not have to make any changes to the component. However, we did have to make changes to the Dockerfile of one of the examples found &lt;a href="https://github.com/kubeflow/pytorch-operator/tree/master/examples/mnist" target="_blank" rel="noopener noreferrer"&gt;here&lt;/a&gt;. We had to add the required folders and permissions to the Dockerfile by doing the following to run the example MNIST test:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Change the Dockerfile to include the following:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;FROM pytorch/pytorch:1.0-cuda10.0-cudnn7-runtime RUN pip install tensorboardX==1.6.0 RUN chmod 777 /var WORKDIR /var ADD mnist.py /var RUN mkdir /data RUN chmod 777 /data ENTRYPOINT ["python", "/var/mnist.py"]&lt;/pre&gt; &lt;ol start="2"&gt; &lt;li&gt;Build and push the Dockerfile to your registry:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;podman build -f Dockerfile -t &amp;#60;your registry name&amp;#62;/pytorch-dist-mnist-test:2.0 ./ podman push &amp;#60;your registry name&amp;#62;/pytorch-dist-mnist-test:2.0&lt;/pre&gt; &lt;ol start="3"&gt; &lt;li&gt;Add the registry image URL to the installation YAML file. We tested this setup without GPU and our file is the following:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;apiVersion: "kubeflow.org/v1" kind: "PyTorchJob" metadata: name: "pytorch-dist-mnist-gloo" spec: pytorchReplicaSpecs: Master: replicas: 1 restartPolicy: OnFailure template: spec: containers: - name: pytorch image: &amp;#60;your registry name&amp;#62;/pytorch-dist-mnist-test:2.0&amp;#60; args: ["--backend", "gloo"] # Comment out the below resources to use the CPU. resources: {} Worker: replicas: 1 restartPolicy: OnFailure template: spec: containers: - name: pytorch image: &amp;#60;your registry name&amp;#62;/pytorch-dist-mnist-test:2.0 args: ["--backend", "gloo"] # Comment out the below resources to use the CPU. resources: {}&lt;/pre&gt; &lt;ol start="4"&gt; &lt;li&gt;Create a PyTorch job by running the command&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;oc create -f v1/&amp;#60;filename.yaml&amp;#62;&lt;/pre&gt; &lt;ol start="5"&gt; &lt;li&gt;Check that the worker and master PyTorch pods are running with no errors.&lt;/li&gt; &lt;/ol&gt; &lt;h4&gt;Tf-jobs&lt;/h4&gt; &lt;p&gt;To get TF-jobs training working on OpenShift we had to add the &lt;code&gt;tfjob/finalizers&lt;/code&gt; resource for the &lt;code&gt;tf-job-operator&lt;/code&gt; ClusterRole for OpenShift to be able to set owner references. Follow these steps to run the example MNIST training job:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Run:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;$ git clone https://github.com/kubeflow/tf-operator $ cd tf-operator/examples/v1/mnist_with_summaries&lt;/pre&gt; &lt;ol start="2"&gt; &lt;li&gt;Create the &lt;code&gt;PersisentVolumeClaim&lt;/code&gt; shown below (we did have to change the &lt;code&gt;acceddModes&lt;/code&gt; to &lt;code&gt;RedWriteOnce&lt;/code&gt; for our cluster):&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;apiVersion: v1 kind: PersistentVolumeClaim metadata: name: tfevent-volume namespace: kubeflow labels:  type: local app: tfjob spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi&lt;/pre&gt; &lt;ol start="3"&gt; &lt;li&gt;Run:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;$ oc apply -f tfevent-volume/&amp;#60;new pvc filename&amp;#62;.yaml $ oc apply -f tf_job_mnist.yaml $ oc describe tfjob mnist Events: Type    Reason                 Age From Message ----    ------                 ---- ---- ------- Normal  SuccessfulCreatePod      12m tf-operator Created pod: mnist-worker-0 Normal  SuccessfulCreateService  12m tf-operator Created service: mnist-worker-0 Normal  ExitedWithCode           11m tf-operator Pod: kubeflow.mnist-worker-0 exited with code 0 Normal  TFJobSucceeded           11m tf-operator TFJob mnist successfully completed.&lt;/pre&gt; &lt;h3&gt;Serving&lt;/h3&gt; &lt;p&gt;For serving, we had to make changes for one of the apps: Seldon&lt;/p&gt; &lt;h4&gt;Seldon&lt;/h4&gt; &lt;p&gt;To get Seldon to work on OpenShift we had to delete the &amp;#8220;8888&amp;#8221; UID value assigned to the engine container that is part of a served model pod. This value dictated that every time a model is served, its engine controller container UID was assigned the value &amp;#8220;8888,&amp;#8221; but that value is not within the allowed range of UID values in OpenShift.&lt;/p&gt; &lt;p&gt;For a quick example to try this issue out for yourself, here is an example fraud detection model:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Create a Seldon deployment YAML file using the following example:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;{ "apiVersion": "machinelearning.seldon.io/v1alpha2", "kind": "SeldonDeployment", "metadata": { "labels": { "app": "seldon" }, "name": "modelfull", "namespace": "kubeflow" }, "spec": { "annotations": { "project_name": "seldon", "deployment_version": "0.1" }, "name": "modelfull", "oauth_key": "oauth-key", "oauth_secret": "oauth-secret", "predictors": [ { "componentSpecs": [{ "spec": { "containers": [ { "image": "nakfour/modelfull", "imagePullPolicy": "Always", "name": "modelfull", "resources": { "requests": { "memory": "10Mi" } } } ], "terminationGracePeriodSeconds": 40 } }], "graph": { "children": [], "name": "modelfull", "endpoint": { "type" : "REST" }, "type": "MODEL" }, "name": "modelfull", "replicas": 1, "annotations": { "predictor_version" : "0.1" } } ] } }&lt;/pre&gt; &lt;ol start="2"&gt; &lt;li&gt;Install this configuration by running:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;$ oc create -f "filename.yaml"&lt;/pre&gt; &lt;ol start="3"&gt; &lt;li&gt;Verify that there is a pod that includes the name &lt;code&gt;modelfull&lt;/code&gt; running.&lt;/li&gt; &lt;li&gt;Verify that there is a virtual service that includes the name &lt;code&gt;modelfull&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;From a terminal, send a &lt;em&gt;predict request&lt;/em&gt; to the model using this example &lt;code&gt;curl&lt;/code&gt; command:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;curl -X POST -H 'Content-Type: application/json' -d '{"strData": "0.365194527642578,0.819750231339882,-0.5927999453145171,-0.619484351930421,-2.84752569239798,1.48432160780265,0.499518887687186,72.98"}' http://"Insert istio ingress domain name"/seldon/kubeflow/modelfull/api/v0.1/predictions&lt;/pre&gt; &lt;h3&gt;Istio&lt;/h3&gt; &lt;p&gt;Installing the default Istio provided with Kubeflow 0.7 required adding a route to the Istio ingress gateway service and the &lt;code&gt;anyuid&lt;/code&gt; security context. These additions give Istio permission to run as a privileged user for the multiple service accounts used by Istio&amp;#8217;s components.&lt;/p&gt; &lt;h2&gt;Next steps&lt;/h2&gt; &lt;p&gt;The Open Data Hub team is currently focused on multiple next steps or tasks:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Resolving component issues already discussed in this document, such as Pipeline and Katib.&lt;/li&gt; &lt;li&gt;Integrating Kubeflow 0.7 with Red Hat Service Mesh on OpenShift 4.2.&lt;/li&gt; &lt;li&gt;Proposing the changes discussed in this document back upstream to the Kubeflow community.&lt;/li&gt; &lt;li&gt;Working with the Kubeflow community to add official OpenShift platform documentation on the &lt;a href="https://www.kubeflow.org/docs/" target="_blank" rel="noopener noreferrer"&gt;Kubeflow website&lt;/a&gt; as a supported platform.&lt;/li&gt; &lt;li&gt;Architecting and designing a solution for tight integration between Open Data Hub and Kubeflow that includes Operator redesign.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F10%2Finstalling-kubeflow-v0-7-on-openshift-4-2%2F&amp;#38;linkname=Installing%20Kubeflow%20v0.7%20on%20OpenShift%204.2" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F10%2Finstalling-kubeflow-v0-7-on-openshift-4-2%2F&amp;#38;linkname=Installing%20Kubeflow%20v0.7%20on%20OpenShift%204.2" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F10%2Finstalling-kubeflow-v0-7-on-openshift-4-2%2F&amp;#38;linkname=Installing%20Kubeflow%20v0.7%20on%20OpenShift%204.2" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F10%2Finstalling-kubeflow-v0-7-on-openshift-4-2%2F&amp;#38;linkname=Installing%20Kubeflow%20v0.7%20on%20OpenShift%204.2" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F10%2Finstalling-kubeflow-v0-7-on-openshift-4-2%2F&amp;#38;linkname=Installing%20Kubeflow%20v0.7%20on%20OpenShift%204.2" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F10%2Finstalling-kubeflow-v0-7-on-openshift-4-2%2F&amp;#38;linkname=Installing%20Kubeflow%20v0.7%20on%20OpenShift%204.2" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F10%2Finstalling-kubeflow-v0-7-on-openshift-4-2%2F&amp;#38;linkname=Installing%20Kubeflow%20v0.7%20on%20OpenShift%204.2" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F10%2Finstalling-kubeflow-v0-7-on-openshift-4-2%2F&amp;#038;title=Installing%20Kubeflow%20v0.7%20on%20OpenShift%204.2" data-a2a-url="https://developers.redhat.com/blog/2020/02/10/installing-kubeflow-v0-7-on-openshift-4-2/" data-a2a-title="Installing Kubeflow v0.7 on OpenShift 4.2"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/10/installing-kubeflow-v0-7-on-openshift-4-2/"&gt;Installing Kubeflow v0.7 on OpenShift 4.2&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/KDXuwXzLVJc" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;As part of the Open Data Hub project, we see potential and value in the Kubeflow project, so we dedicated our efforts to enable Kubeflow on Red Hat OpenShift. We decided to use Kubeflow 0.7 as that was the latest released version at the time this work began. The work included adding new installation scripts [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/10/installing-kubeflow-v0-7-on-openshift-4-2/"&gt;Installing Kubeflow v0.7 on OpenShift 4.2&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">679917</post-id><dc:creator>Juana Nakfour</dc:creator><dc:date>2020-02-10T08:00:14Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/02/10/installing-kubeflow-v0-7-on-openshift-4-2/</feedburner:origLink></entry><entry><title>Integrating with SaaS Applications - Common Architectural Elements</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/3okRjSKFLa0/integrating-saas-applications-common-architectural-elements.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Architecture Blueprints" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="cloud" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="FUSE" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="Process Automation Manager" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-integrating_with_saas_applications_common_architectural_elements</id><updated>2020-02-10T06:00:00Z</updated><published>2020-02-10T06:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div style="text-align: left;"&gt;&lt;/div&gt;&lt;table cellpadding="0" cellspacing="0" class="tr-caption-container" style="float: left; margin-right: 1em; text-align: left;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-AzXG8srNP44/Xj-t6bgALLI/AAAAAAAABnw/lgKidHnFpYYF8hikQzFZIgT313nlBAgiACLcBGAsYHQ/s1600/integrate-saas-apps-ld.png" imageanchor="1" style="clear: left; margin-bottom: 1em; margin-left: auto; margin-right: auto;"&gt;&lt;img alt="integrating with SaaS applications" border="0" data-original-height="900" data-original-width="1600" height="180" src="https://1.bp.blogspot.com/-AzXG8srNP44/Xj-t6bgALLI/AAAAAAAABnw/lgKidHnFpYYF8hikQzFZIgT313nlBAgiACLcBGAsYHQ/s320/integrate-saas-apps-ld.png" title="" width="320" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;Part 2 - Common architectural elements&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;The introduction to integrating with SaaS applications laid out groundwork for a deeper exploration of it's logical diagram.&lt;br /&gt;&lt;br /&gt;In this article we continue with a look at the common architectural elements. A description is provided to guide you with aligning what we've presented here with the landscape your organization works with every day.&lt;br /&gt;&lt;br /&gt;These details should help you understand both what the elements contain and how they might align and how their functionalities are grouped.&lt;br /&gt;&lt;br /&gt;Let's look at the foundation of our integrate with SaaS applications blueprint, the logical diagram with it's architectural elements.&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;&lt;a href="https://1.bp.blogspot.com/-S1_exoN52YU/Xj-wlDqS7pI/AAAAAAAABn8/bBtjGHwZU9YiCy2D7Jc5Gglt6almVF2bACLcBGAsYHQ/s1600/exerntal-apps.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="integrating with SaaS applications" border="0" data-original-height="504" data-original-width="1050" height="95" src="https://1.bp.blogspot.com/-S1_exoN52YU/Xj-wlDqS7pI/AAAAAAAABn8/bBtjGHwZU9YiCy2D7Jc5Gglt6almVF2bACLcBGAsYHQ/s200/exerntal-apps.png" title="" width="200" /&gt;&lt;/a&gt;External applications&lt;/h3&gt;&lt;div&gt;There is one element in this category of external applications and it's meant to encompass the applications external to our systems. &lt;br /&gt;&lt;br /&gt;These can be any applications provided by the organization or third parties connecting with internal services.&lt;br /&gt;&lt;br /&gt;These are applications that can operating outside of the organization's infrastructure, or as internal employee interfaces to the organizational services. Can include IVR, text, chatbots, etc. We've seen many instances of these applications and decides to group them in one element fronting all external actions that trigger a need for integrating with SaaS applications.&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href="https://1.bp.blogspot.com/-4_VAmayVOYM/Xj-wqSdaBXI/AAAAAAAABoA/MBL5F7GHlfsZgoMtA5hrgb2ZLmYVCSTTQCLcBGAsYHQ/s1600/container-platform.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="integrating with SaaS applications" border="0" data-original-height="598" data-original-width="1600" height="119" src="https://1.bp.blogspot.com/-4_VAmayVOYM/Xj-wqSdaBXI/AAAAAAAABoA/MBL5F7GHlfsZgoMtA5hrgb2ZLmYVCSTTQCLcBGAsYHQ/s320/container-platform.png" title="" width="320" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Container platform services&lt;/h3&gt;&lt;div&gt;A group of elements are collected here in the container platform and provide essential services to external applications.&lt;br /&gt;&lt;br /&gt;Note that each element covers a microservice collection and in most cases are discussed as a group of microservices without detailing or splitting out single specific services.&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;&lt;i&gt;Frontend microservices:&lt;/i&gt; Interface of business logic, mobile clients and orchestration calls to back end components.&lt;i&gt;&amp;nbsp;&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;Process microservices:&lt;/i&gt; Services for orchestration using deployed process automation services.&lt;/li&gt;&lt;li&gt;&lt;i&gt;Integration data microservices:&lt;/i&gt; Providing abstraction between front end services and internal storage.&amp;nbsp;&lt;/li&gt;&lt;li&gt;&lt;i&gt;Integration microservices:&lt;/i&gt; Providing abstraction between front end services and external systems. &lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;As these microservices would likely be specific to each organizations needs, it's helpful enough to understand their groupings without worrying about functional details.&lt;br /&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Infrastructure services&lt;/h3&gt;&lt;div&gt;&lt;a href="https://1.bp.blogspot.com/-HZyzj_1rbIw/Xj-w1nkFC-I/AAAAAAAABoM/zP7OdnO2irMjv72sCMevzjtB3j9lIMcTwCLcBGAsYHQ/s1600/infra-services.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="integrating with SaaS applications" border="0" data-original-height="1560" data-original-width="1098" height="320" src="https://1.bp.blogspot.com/-HZyzj_1rbIw/Xj-w1nkFC-I/AAAAAAAABoM/zP7OdnO2irMjv72sCMevzjtB3j9lIMcTwCLcBGAsYHQ/s320/infra-services.png" title="" width="225" /&gt;&lt;/a&gt;These services are grouped into infrastructure as they provide core functionality that cross many system boundaries and / or are embedded with the help of code plugins.&lt;br /&gt;&lt;br /&gt;Some are physical servers or platforms that support services across the organization and others have a coordinating function.&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;&lt;i&gt;API management:&lt;/i&gt; Manage and expose APIs for microservice and application interface availability.&lt;/li&gt;&lt;li&gt;&lt;i&gt;External SaaS CRM:&lt;/i&gt; External customer resource management (CRM) system exposing an API.&lt;/li&gt;&lt;li&gt;&lt;i&gt;3rd party services platform:&lt;/i&gt; A platform hosted with services for entire organization, legacy architecture choice.&lt;/li&gt;&lt;li&gt;&lt;i&gt;Single-sign-on (SSO) server:&lt;/i&gt; Single-Sign-On server, supporting code plugins.&lt;/li&gt;&lt;li&gt;&lt;i&gt;Storage:&lt;/i&gt; Large unstructured data or file storage local or cloud-based as needed by applications, processes or services.&lt;/li&gt;&lt;/ul&gt;As we look in to the more detailed schematic diagrams of specific use cases, not all of these infrastructure elements are apparent, but they are core to the successful integrating with SaaS applications solutions.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;/div&gt;&lt;h3&gt;&lt;/h3&gt;&lt;/div&gt;&lt;h3&gt;What's next&lt;/h3&gt;&lt;ul style="text-align: left;"&gt;&lt;/ul&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;An overview of the series on integrating SaaS applications portfolio architecture blueprint can be found here:&lt;br /&gt;&lt;ol style="text-align: left;"&gt;&lt;li&gt;&lt;a href="https://www.schabell.org/2020/01/integrating-saas-applications-an-introduction.html" target="_blank"&gt;An introduction&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.schabell.org/2020/02/integrating-saas-applications-common-architectural-elements.html" target="_blank"&gt;Common architectural elements&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Example external CRM integration&lt;/li&gt;&lt;li&gt;Example 3rd-party platform integration&lt;/li&gt;&lt;li&gt;Example processes with 3rd-party platform integration&lt;/li&gt;&lt;/ol&gt;Catch up on any articles you missed by following one of the links above.&lt;br /&gt;&lt;br /&gt;Next in this series, taking a look at the generic common architecture to integrate SaaS applications. &lt;/div&gt;&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=061Q1qc_YGM:q6WSD8jv_wc:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=061Q1qc_YGM:q6WSD8jv_wc:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=061Q1qc_YGM:q6WSD8jv_wc:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=061Q1qc_YGM:q6WSD8jv_wc:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=061Q1qc_YGM:q6WSD8jv_wc:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=061Q1qc_YGM:q6WSD8jv_wc:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=061Q1qc_YGM:q6WSD8jv_wc:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=061Q1qc_YGM:q6WSD8jv_wc:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=061Q1qc_YGM:q6WSD8jv_wc:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=061Q1qc_YGM:q6WSD8jv_wc:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=061Q1qc_YGM:q6WSD8jv_wc:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/061Q1qc_YGM" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/3okRjSKFLa0" height="1" width="1" alt=""/&gt;</content><summary>Part 2 - Common architectural elementsThe introduction to integrating with SaaS applications laid out groundwork for a deeper exploration of it's logical diagram. In this article we continue with a look at the common architectural elements. A description is provided to guide you with aligning what we've presented here with the landscape your organization works with every day. These details should ...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2020-02-10T06:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/061Q1qc_YGM/integrating-saas-applications-common-architectural-elements.html</feedburner:origLink></entry><entry><title>JBoss Editorial (February 7th): Quarkus, Camel, Keycloak and Kie</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/fWzLWw6Z370/jboss-editorial-february-7th-quarkus-camel-keycloak-and-kie" /><category term="Camel" scheme="searchisko:content:tags" /><category term="camel-k" scheme="searchisko:content:tags" /><category term="Decision Manager" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_weeklyeditorial" scheme="searchisko:content:tags" /><category term="jgroups" scheme="searchisko:content:tags" /><category term="jwt" scheme="searchisko:content:tags" /><category term="keycloak" scheme="searchisko:content:tags" /><category term="news" scheme="searchisko:content:tags" /><category term="Process Automation Manager" scheme="searchisko:content:tags" /><category term="quarkus" scheme="searchisko:content:tags" /><category term="weekly_editorial" scheme="searchisko:content:tags" /><category term="weekly_update" scheme="searchisko:content:tags" /><author><name>Kevin Conner</name></author><id>searchisko:content:id:jbossorg_blog-jboss_editorial_february_7th_quarkus_camel_keycloak_and_kie</id><updated>2020-02-07T23:55:07Z</updated><published>2020-02-07T23:55:07Z</published><content type="html">&lt;!-- [DocumentBodyStart:31e0f10d-75c9-4183-983c-a0e055494868] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;p style="font-family: Cabin;"&gt;Welcome to another edition of the JBoss Editorial, our regular tour through the JBoss Communities in search of news and developments from the community projects.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px; font-family: Cabin;"&gt;&amp;#160;&lt;/p&gt;&lt;h2 style="font-family: Cabin;"&gt;Quarkus Tools for Visual Studio Code&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px; font-family: Cabin;"&gt;&amp;#160;&lt;/p&gt;&lt;p style="font-family: Cabin;"&gt;Quarkus Tools for Visual Studio Code 1.3.0 has now been released on the VS Code Marketplace, bringing with it many new features accompanying the evolution of Quarkus.&amp;#160; &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2020/02/07/introducing-10-new-features-in-quarkus-tools-for-visual-studio-code/" rel="nofollow"&gt;David provides a summary of the major improvements in this release&lt;/a&gt; as well as a &lt;a class="jive-link-external-small" href="https://youtu.be/6SZPJOaswtA" rel="nofollow"&gt;demo video&lt;/a&gt; which covers the features presented in his article.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px; font-family: Cabin;"&gt;&amp;#160;&lt;/p&gt;&lt;h2 style="font-family: Cabin;"&gt;Camel and Camel K&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px; font-family: Cabin;"&gt;&amp;#160;&lt;/p&gt;&lt;p style="font-family: Cabin;"&gt;Claus has written an update to his first blog discussing the optimisations which they are making in the Camel 3.1 release, &lt;a class="jive-link-external-small" href="http://www.davsclaus.com/2020/01/apache-camel-31-more-camel-core_30.html" rel="nofollow"&gt;providing a status update on progress as they drive towards fewer object allocations, method invocations and improved performance&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px; font-family: Cabin;"&gt;&amp;#160;&lt;/p&gt;&lt;p style="font-family: Cabin;"&gt;Aur&amp;eacute;lien has written an article &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2020/01/24/apache-camel-k-development-inside-eclipse-che-iteration-1/" rel="nofollow"&gt;describing the first iteration of Apache Camel K integration within Eclipse Che 7.6.0&lt;/a&gt;.&amp;#160; The article covers how to set up the Che instance, create a new workspace and deploy a Camel K integration within the Che environment.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px; font-family: Cabin;"&gt;&amp;#160;&lt;/p&gt;&lt;p style="font-family: Cabin;"&gt;Deploying Camel K integrations in a lightweight manner can be supported through the support of standalone Java files describing the integration, however this comes with the downside that existing IDEs will not provide complete support out of the box.&amp;#160; There are already a number of solutions to this problem albeit without any intuitive configuration.&amp;#160; &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2020/02/03/camel-k-standalone-java-file-now-with-java-language-support/" rel="nofollow"&gt;Red Hat's Tooling for Apache Camel K offers a new solution to this problem with support for the Java language now being included&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px; font-family: Cabin;"&gt;&amp;#160;&lt;/p&gt;&lt;h2 style="font-family: Cabin;"&gt;Keycloak and JWT Tokens&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px; font-family: Cabin;"&gt;&amp;#160;&lt;/p&gt;&lt;p style="font-family: Cabin;"&gt;Muhammed has written a great article demonstrating how easy &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2020/01/29/api-login-and-jwt-token-generation-using-keycloak/" rel="nofollow"&gt;Keycloak can be used as to obtain JWT tokens through a login process&lt;/a&gt;.&amp;#160; Muhammed begins with Keycloak configuration for users and clients before demonstrating client side login and retrieval of the JWT token.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px; font-family: Cabin;"&gt;&amp;#160;&lt;/p&gt;&lt;h2 style="font-family: Cabin;"&gt;Decision Manager and Process Automation Manager&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px; font-family: Cabin;"&gt;&amp;#160;&lt;/p&gt;&lt;p style="font-family: Cabin;"&gt;Eric has revamped his installer scripts to support the latest versions of &lt;a class="jive-link-external-small" href="https://www.schabell.org/2020/01/how-to-install-red-hat-decision-manager-76-in-minutes.html" rel="nofollow"&gt;Decision Manager&lt;/a&gt; and &lt;a class="jive-link-external-small" href="https://www.schabell.org/2020/01/how-to-install-red-hat-process-automation-manager-76-in-minutes.html" rel="nofollow"&gt;Process Automation Manager&lt;/a&gt;, setting up local environments for both environments in three easy steps; download, unzip and run the init scripts to get started!!&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px; font-family: Cabin;"&gt;&amp;#160;&lt;/p&gt;&lt;p style="font-family: Cabin;"&gt;Guilherme has also announced the &lt;a class="jive-link-external-small" href="http://blog.athico.com/2020/02/kie-decision-tooling-blog.html" rel="nofollow"&gt;KIE Decision Tooling blog for those who want to find out more about the team building web editors to support business decisions&lt;/a&gt;, their first post discussing the new code completion feature in the DMN editor.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px; font-family: Cabin;"&gt;&amp;#160;&lt;/p&gt;&lt;h2 style="font-family: Cabin;"&gt;New Releases&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;The &lt;a class="jive-link-external-small" href="http://jgroups.org/" rel="nofollow"&gt;JGroups&lt;/a&gt; team announce the &lt;a class="jive-link-external-small" href="https://belaban.blogspot.com/2020/01/first-alpha-of-jgroups-50.html" rel="nofollow"&gt;first alpha release of JGroups 5.0&lt;/a&gt;.&lt;/li&gt;&lt;li&gt;The &lt;a class="jive-link-external-small" href="https://www.keycloak.org/" rel="nofollow"&gt;Keycloak&lt;/a&gt; team announce the &lt;a class="jive-link-external-small" href="https://www.keycloak.org/2020/02/keycloak-802-released.html" rel="nofollow"&gt;release of Keycloak 8.0.2&lt;/a&gt;.&lt;/li&gt;&lt;/ul&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;That's all we have for this edition of the Editorial, please join us next time for another journey through the JBoss Communities in search of more exciting updates.&lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:31e0f10d-75c9-4183-983c-a0e055494868] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/fWzLWw6Z370" height="1" width="1" alt=""/&gt;</content><summary>Welcome to another edition of the JBoss Editorial, our regular tour through the JBoss Communities in search of news and developments from the community projects.   Quarkus Tools for Visual Studio Code   Quarkus Tools for Visual Studio Code 1.3.0 has now been released on the VS Code Marketplace, bringing with it many new features accompanying the evolution of Quarkus.  David provides a summary of t...</summary><dc:creator>Kevin Conner</dc:creator><dc:date>2020-02-07T23:55:07Z</dc:date><feedburner:origLink>https://developer.jboss.org/blogs/weekly-editorial/2020/02/07/jboss-editorial-february-7th-quarkus-camel-keycloak-and-kie</feedburner:origLink></entry><entry><title>Introducing 10 new features in Quarkus Tools for Visual Studio Code</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/2p-wroBeVWk/" /><category term="Developer Tools" /><category term="Modern App Dev" /><category term="VS Code" /><category term="Kubernetes" /><category term="openshift" /><category term="quarkus tools" /><category term="qute" /><category term="Visual Studio Code" /><author><name>David Kwon</name></author><id>https://developers.redhat.com/blog/?p=676617</id><updated>2020-02-07T08:00:07Z</updated><published>2020-02-07T08:00:07Z</published><content type="html">&lt;p&gt;Quarkus Tools for Visual Studio Code version 1.3.0 has been released on the VS Code Marketplace to start off the new year. As Quarkus continues to introduce improvements and new features like &lt;code&gt;application.yaml&lt;/code&gt; and server-side templating support, Quarkus Tools for Visual Studio Code continues to evolve to accompany these new features and improvements.&lt;/p&gt; &lt;p&gt;For a list of all changes, please refer to the &lt;a href="https://github.com/redhat-developer/vscode-quarkus/blob/master/CHANGELOG.md" target="_blank" rel="noopener noreferrer"&gt;changelog&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;You can also &lt;a href="https://youtu.be/6SZPJOaswtA" target="_blank" rel="noopener noreferrer"&gt;watch a demo video&lt;/a&gt; of all the features presented in this article.&lt;/p&gt; &lt;h2&gt;New features&lt;/h2&gt; &lt;p&gt;The new features added to Quarkus Tools for Visual Studio Code 1.3.0 include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A new URL CodeLens for RESTEasy JAX-RS GET methods.&lt;/li&gt; &lt;li&gt;Hover support for &lt;code&gt;@ConfigProperty&lt;/code&gt; name in Java sources.&lt;/li&gt; &lt;li&gt;MicroProfile properties support for the REST Client.&lt;/li&gt; &lt;li&gt;Kubernetes, &lt;a href="http://developers.redhat.com/openshift/" target="_blank" rel="noopener noreferrer"&gt;Red Hat OpenShift&lt;/a&gt;, Docker, and S2I property support.&lt;/li&gt; &lt;li&gt;A Quick Fix to add unknown property namespaces to ignore.&lt;/li&gt; &lt;li&gt;Go to definition support for enum values from &lt;code&gt;application.properties&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;YAML support (experimental).&lt;/li&gt; &lt;li&gt;A new extension descriptions toggle button.&lt;/li&gt; &lt;li&gt;Different ways to open a new Quarkus project.&lt;/li&gt; &lt;li&gt;Syntax highlighting for Qute languages.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;URL CodeLens for RESTEasy JAX-RS GET methods&lt;/h2&gt; &lt;p&gt;When editing a resource class while the current Quarkus application is running in development mode (&lt;code&gt;./mvnw compile quarkus:dev&lt;/code&gt; or &lt;code&gt;./gradlew quarkusDev&lt;/code&gt;), there are now CodeLenses that provide the URL for the GET endpoints. This feature takes into account the pathname and the HTTP server port in your &lt;code&gt;application.properties&lt;/code&gt; file in order to create the URL.&lt;/p&gt; &lt;p&gt;Clicking on the CodeLens URL opens this URL in your default browser, as shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_676737" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-676737" class="wp-image-676737" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/codelensURL-min.gif" alt="Animation showing edits, and then clicking to open the URL." width="640" height="390" /&gt;&lt;p id="caption-attachment-676737" class="wp-caption-text"&gt;Figure 1: Clicking the CodeLens URL opens it in your default browser.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Once the Quarkus application stops running, the CodeLens URL will no longer appear, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_676727" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-676727" class="wp-image-676727" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/codelensURL2-min.gif" alt="Animation showing edits and then the missing CodeLens URL." width="640" height="390" /&gt;&lt;p id="caption-attachment-676727" class="wp-caption-text"&gt;Figure 2: The CodeLens URL disappears once the Quarkus application stops running.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Please keep in mind that CodeLenses in VS Code are only updated when certain events happen. If the URL CodeLens does not appear, there are two easy ways to trigger a CodeLens update: switch tabs or start typing in any file. Also, make sure that the &lt;code&gt;quarkus.tools.codeLens.urlCodeLensEnabled&lt;/code&gt; VS Code setting is set to &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Hover support for &lt;code&gt;@ConfigProperty&lt;/code&gt; name in Java sources&lt;/h2&gt; &lt;p&gt;Hovering over the name value in a &lt;code&gt;@ConfigProperty&lt;/code&gt; annotation now displays the hovered property&amp;#8217;s value, as shown in Figure 3. Currently, the value either comes from &lt;code&gt;application.properties&lt;/code&gt; file, or the default value field.&lt;/p&gt; &lt;div id="attachment_676767" style="width: 651px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-676767" class="wp-image-676767" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/hoverconfigproperty-min.gif" alt="Animation showing that you can hover over these name values to see the property's value." width="641" height="390" /&gt;&lt;p id="caption-attachment-676767" class="wp-caption-text"&gt;Figure 3: Hover over a &lt;code&gt;@ConfigProperty&lt;/code&gt; annotation&amp;#8217;s name value to display the hovered property&amp;#8217;s value.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;MicroProfile properties support for the REST Client&lt;/h2&gt; &lt;p&gt;There is now completion, hover, documentation, and validation for the MicroProfile properties from the REST Client. After registering a REST Client using &lt;code&gt;@RegisterRestClient&lt;/code&gt; like so:&lt;/p&gt; &lt;pre&gt;package com.mycompany.remoteServices; @RegisterRestClient public interface MyServiceClient { @GET @Path("/greet") String greet(); }&lt;/pre&gt; &lt;p&gt;Language features will become available for the related MicroProfile config properties, as shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_682477" style="width: 649px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-682477" class="wp-image-682477" src="https://developers.redhat.com/blog/wp-content/uploads/2020/02/MPRest.gif" alt="Animation showing the new properties available in the extension." width="639" height="271" /&gt;&lt;p id="caption-attachment-682477" class="wp-caption-text"&gt;Figure 4: Language features for the new properties.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;More information about using the MicroProfile REST Client is available in the Quarkus guides &lt;a href="https://quarkus.io/guides/rest-client" target="_blank" rel="noopener noreferrer"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Kubernetes, Openshift, Docker, and S2I property support&lt;/h2&gt; &lt;p&gt;Likewise, there is now completion, hover, documentation, and validation for the &lt;code&gt;kubernetes.*&lt;/code&gt;, &lt;code&gt;openshift.*&lt;/code&gt;, &lt;code&gt;docker.*&lt;/code&gt;, and &lt;code&gt;s2i.*&lt;/code&gt; properties coming from the &lt;a href="https://quarkus.io/guides/kubernetes#enable-kubernetes-support" target="_blank" rel="noopener noreferrer"&gt;Kubernetes Quarkus extension&lt;/a&gt;, as shown in Figure 5.&lt;/p&gt; &lt;div id="attachment_676777" style="width: 649px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-676777" class="wp-image-676777" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/kubopedocs2i-min.gif" alt="Animation showing the new properties available in the extension." width="639" height="271" /&gt;&lt;p id="caption-attachment-676777" class="wp-caption-text"&gt;Figure 5: Languages features for the new properties.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In-depth documentation about generating Kubernetes resources and the config properties involved can be found in the Quarkus guides &lt;a href="https://quarkus.io/guides/kubernetes#configuration-options" target="_blank" rel="noopener noreferrer"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Quick Fix to add unknown property namespaces to ignore&lt;/h2&gt; &lt;p&gt;There is now a new Quick Fix that helps you exclude large groups of unknown properties from unknown property validation, as long as they share the same parent namespace. For example, if your &lt;code&gt;application.properties&lt;/code&gt; file contains four properties with an unknown property error, like so:&lt;/p&gt; &lt;pre&gt;# All four properties cause an 'Unknown property' error unknown.test1=a unknown.test2=b unknown.test3=c unknown.test4=d&lt;/pre&gt; &lt;p&gt;Ignoring all four properties from unknown property validation is easily done with the Quick Fix, which adds &lt;code&gt;unknown.*&lt;/code&gt; to the &lt;code&gt;quarkus.tools.validation.unknown.excluded&lt;/code&gt; workspace configuration array, as shown in Figure 6.&lt;/p&gt; &lt;div id="attachment_676797" style="width: 649px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-676797" class="wp-image-676797" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/codeaction.gif" alt="Animation showing how you can ignore certain properties." width="639" height="389" /&gt;&lt;p id="caption-attachment-676797" class="wp-caption-text"&gt;Figure 6: Ignoring properties from unknown property validation.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Go to definition support for enum values from &lt;code&gt;application.properties&lt;/code&gt;&lt;/h2&gt; &lt;p&gt;Up until now, Go to definition was only supported for config property keys and not their values. This release brings the Go to definition feature for enum values, as shown in Figure 7.&lt;/p&gt; &lt;div id="attachment_676817" style="width: 649px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-676817" class="wp-image-676817" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/enumvalue.gif" alt="Animation showing how to use the definition features for enum values." width="639" height="462" /&gt;&lt;p id="caption-attachment-676817" class="wp-caption-text"&gt;Figure 7: Using the Go to definition feature with enum values.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;YAML support (experimental)&lt;/h2&gt; &lt;p&gt;The release of &lt;a href="https://quarkus.io/blog/quarkus-1-1-0-final-released/" target="_blank" rel="noopener noreferrer"&gt;Quarkus 1.1.0.Final&lt;/a&gt;, brought &lt;a href="https://quarkus.io/guides/config#yaml" target="_blank" rel="noopener noreferrer"&gt;YAML configuration support&lt;/a&gt;, meaning that you can now configure your Quarkus application with either an &lt;code&gt;application.yaml&lt;/code&gt; file or an &lt;code&gt;application.properties&lt;/code&gt; file (but try to stick with one or the other).&lt;/p&gt; &lt;p&gt;As a result, there is now completion support for &lt;code&gt;application.yaml&lt;/code&gt; files, as shown in Figure 8. Similar to &lt;code&gt;application.properties&lt;/code&gt;, the completion options in &lt;code&gt;application.yaml&lt;/code&gt; file will be in sync with the Quarkus extensions that are available to the current project at the time (in &lt;code&gt;pom.xml&lt;/code&gt; or &lt;code&gt;build.gradle&lt;/code&gt;), therefore giving you only the relevant completion options.&lt;/p&gt; &lt;p&gt;This feature depends on the &lt;a href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-yaml" target="_blank" rel="noopener noreferrer"&gt;YAML Language Support by Red Hat&lt;/a&gt; extension. If it is not currently installed, a new prompt will propose to install it.&lt;/p&gt; &lt;div id="attachment_682807" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-682807" class="wp-image-682807 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/02/yamlcompletion_gif.gif" alt="Animation showing the completion support in use." width="640" height="313" /&gt;&lt;p id="caption-attachment-682807" class="wp-caption-text"&gt;Figure 8: New completion support for the &lt;code&gt;application.yaml&lt;/code&gt; file.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Language feature support for &lt;code&gt;application.yaml&lt;/code&gt; files is in its experimental stages. Compared to &lt;code&gt;application.properties&lt;/code&gt; support, there are missing features:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Go to definition support.&lt;/li&gt; &lt;li&gt;Code action support.&lt;/li&gt; &lt;li&gt;Automatic completion for default values.&lt;/li&gt; &lt;li&gt;Limited config property and value validation support.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;A new extension descriptions toggle button&lt;/h2&gt; &lt;p&gt;As the number of Quarkus extensions continues to rise, the new extension descriptions in the extension selection prompt help you recognize and discover new extensions, as shown in Figure 9. The extension selection prompt appears when selecting Quarkus extensions from the &lt;strong&gt;Quarkus: Generate a Quarkus project&lt;/strong&gt; and &lt;strong&gt;Quarkus: Add extensions to current project&lt;/strong&gt; wizards.&lt;/p&gt; &lt;div id="attachment_676867" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-676867" class="wp-image-676867 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/extensions_before_after_text-1024x316.png" alt="Animation showing extension discovery before and after this release." width="640" height="198" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/extensions_before_after_text-1024x316.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/extensions_before_after_text-300x93.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/extensions_before_after_text-768x237.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/extensions_before_after_text.png 1114w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-676867" class="wp-caption-text"&gt;Figure 9: Discover new extensions with the new descriptions.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;There is also a new button on the top right of the selection box that toggles whether or not the extension descriptions should appear, as shown in Figure 10.&lt;/p&gt; &lt;div id="attachment_682487" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-682487" class="wp-image-682487 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/02/toggle_gif.gif" alt="Animation showing how to use the toggle for extension descriptions." width="640" height="307" /&gt;&lt;p id="caption-attachment-682487" class="wp-caption-text"&gt;Figure 10: Toggle whether or not extension descriptions should appear.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Different ways to open a new Quarkus project&lt;/h2&gt; &lt;p&gt;After creating a new project with the &lt;strong&gt;Quarkus: Generate a Quarkus project&lt;/strong&gt; wizard, there is now a new prompt that asks how the new project should be opened. The following &lt;em&gt;before&lt;/em&gt; and &lt;em&gt;after&lt;/em&gt; diagrams describe the changes:&lt;/p&gt; &lt;div id="attachment_682437" style="width: 649px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-682437" class="wp-image-682437" src="https://developers.redhat.com/blog/wp-content/uploads/2020/02/gen_before_updated.png" alt="'Before' diagram." width="639" height="388" /&gt;&lt;p id="caption-attachment-682437" class="wp-caption-text"&gt;Figure 11: &lt;em&gt;(Before)&lt;/em&gt; Scenarios and options provided when generating a new Quarkus project.&lt;/p&gt;&lt;/div&gt; &lt;div id="attachment_682417" style="width: 649px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-682417" class="wp-image-682417" src="https://developers.redhat.com/blog/wp-content/uploads/2020/02/gen_after_updated.png" alt="'After' diagram." width="639" height="388" /&gt;&lt;p id="caption-attachment-682417" class="wp-caption-text"&gt;Figure 12: &lt;em&gt;(After)&lt;/em&gt; Scenarios and options provided when generating a new Quarkus project.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;To help visualize one of the possible scenarios, Figure 13 shows the options presented when generating a project while a workspace is open.&lt;/p&gt; &lt;div id="attachment_676907" style="width: 649px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-676907" class="wp-image-676907" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/newproject.gif" alt="Animation of the new options provided when generating a project." width="639" height="388" /&gt;&lt;p id="caption-attachment-676907" class="wp-caption-text"&gt;Figure 13: Creating a new project with the &lt;strong&gt;Quarkus: Generate a Quarkus project&lt;/strong&gt; wizard.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Syntax highlighting for Qute languages&lt;/h2&gt; &lt;p&gt;&lt;a href="https://quarkus.io/guides/qute-reference" target="_blank" rel="noopener noreferrer"&gt;Qute&lt;/a&gt; is a new server-side templating engine created with Quarkus in mind. This release brings new Qute language modes in VS Code: Qute HTML, Qute JSON, Qute YAML, and Qute Text. These new language modes are automatically applied to your current file if your file’s extension is &lt;code&gt;.qute.html&lt;/code&gt;, &lt;code&gt;.qute.json&lt;/code&gt;, &lt;code&gt;.qute.yaml&lt;/code&gt;, or &lt;code&gt;.qute.txt&lt;/code&gt; respectively.&lt;/p&gt; &lt;p&gt;Thanks to the new language modes, Qute-specific syntax highlighting and commenting are now provided, as shown in Figure 14.&lt;/p&gt; &lt;div id="attachment_682497" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-682497" class="wp-image-682497 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/02/qute_gif.gif" alt="Animation showing Qute-specific syntax highlighting and commenting." width="640" height="331" /&gt;&lt;p id="caption-attachment-682497" class="wp-caption-text"&gt;Figure 14: Qute-specific syntax highlighting and commenting.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;For more information about the Qute templating engine, please refer to the &lt;a href="https://quarkus.io/guides/qute" target="_blank" rel="noopener noreferrer"&gt;Quarkus templating engine guide&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Moving forward&lt;/h2&gt; &lt;p&gt;This wraps up the new major features in this release. If you have any suggestions or feedback, please feel free to &lt;a href="https://github.com/redhat-developer/vscode-quarkus/issues/new" target="_blank" rel="noopener noreferrer"&gt;open a GitHub issue&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;For future releases, alongside general enhancements, we aim to bring more robust language feature support for &lt;code&gt;application.yaml&lt;/code&gt; and Qute languages. Stay tuned for the next release!&lt;/p&gt; &lt;h2&gt;Links&lt;/h2&gt; &lt;p&gt;Here are the important links:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-quarkus" target="_blank" rel="noopener noreferrer"&gt;VS Code Marketplace&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/redhat-developer/vscode-quarkus" target="_blank" rel="noopener noreferrer"&gt;GitHub repository&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/redhat-developer/vscode-quarkus/issues/new" target="_blank" rel="noopener noreferrer"&gt;Open a GitHub issue&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/redhat-developer/vscode-quarkus/blob/master/CHANGELOG.md" target="_blank" rel="noopener noreferrer"&gt;Changelog&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/11/21/new-features-in-quarkus-tools-for-visual-studio-code-1-2-0/"&gt;Version 1.2.0 release article&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/09/23/how-the-new-quarkus-extension-for-visual-studio-code-improves-the-development-experience/"&gt;Version 1.0.0 release article&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F07%2Fintroducing-10-new-features-in-quarkus-tools-for-visual-studio-code%2F&amp;#38;linkname=Introducing%2010%20new%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F07%2Fintroducing-10-new-features-in-quarkus-tools-for-visual-studio-code%2F&amp;#38;linkname=Introducing%2010%20new%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F07%2Fintroducing-10-new-features-in-quarkus-tools-for-visual-studio-code%2F&amp;#38;linkname=Introducing%2010%20new%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F07%2Fintroducing-10-new-features-in-quarkus-tools-for-visual-studio-code%2F&amp;#38;linkname=Introducing%2010%20new%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F07%2Fintroducing-10-new-features-in-quarkus-tools-for-visual-studio-code%2F&amp;#38;linkname=Introducing%2010%20new%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F07%2Fintroducing-10-new-features-in-quarkus-tools-for-visual-studio-code%2F&amp;#38;linkname=Introducing%2010%20new%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F07%2Fintroducing-10-new-features-in-quarkus-tools-for-visual-studio-code%2F&amp;#38;linkname=Introducing%2010%20new%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F07%2Fintroducing-10-new-features-in-quarkus-tools-for-visual-studio-code%2F&amp;#038;title=Introducing%2010%20new%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code" data-a2a-url="https://developers.redhat.com/blog/2020/02/07/introducing-10-new-features-in-quarkus-tools-for-visual-studio-code/" data-a2a-title="Introducing 10 new features in Quarkus Tools for Visual Studio Code"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/07/introducing-10-new-features-in-quarkus-tools-for-visual-studio-code/"&gt;Introducing 10 new features in Quarkus Tools for Visual Studio Code&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/2p-wroBeVWk" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Quarkus Tools for Visual Studio Code version 1.3.0 has been released on the VS Code Marketplace to start off the new year. As Quarkus continues to introduce improvements and new features like application.yaml and server-side templating support, Quarkus Tools for Visual Studio Code continues to evolve to accompany these new features and improvements. For a [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/07/introducing-10-new-features-in-quarkus-tools-for-visual-studio-code/"&gt;Introducing 10 new features in Quarkus Tools for Visual Studio Code&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">676617</post-id><dc:creator>David Kwon</dc:creator><dc:date>2020-02-07T08:00:07Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/02/07/introducing-10-new-features-in-quarkus-tools-for-visual-studio-code/</feedburner:origLink></entry></feed>
